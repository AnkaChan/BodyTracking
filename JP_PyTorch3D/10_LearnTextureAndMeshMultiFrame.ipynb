{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:96% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.2\n",
      "[04/15 14:55:31]\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "import imageio\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "from pytorch3d.loss import (\n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "# Util function for loading meshes\n",
    "from pytorch3d.io import load_objs_as_meshes, load_obj\n",
    "import math\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Meshes, Textures, join_meshes\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    OpenGLPerspectiveCameras, \n",
    "    SfMPerspectiveCameras,\n",
    "    SfMOrthographicCameras,\n",
    "    PointLights, \n",
    "    DirectionalLights,\n",
    "    Materials, \n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer,  \n",
    "    TexturedSoftPhongShader,\n",
    "    SoftSilhouetteShader,\n",
    "    look_at_rotation,\n",
    "    HardFlatShader\n",
    ")\n",
    "\n",
    "# add path for demo utils functions \n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "sys.path.append(os.path.abspath(''))\n",
    "\n",
    "print(torch.version.cuda)\n",
    "from datetime import datetime\n",
    "def now_str():\n",
    "    now = datetime.now()\n",
    "    month = str(now.month)\n",
    "    day = str(now.day)\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    sec = str(now.second)\n",
    "    \n",
    "    output = '[{:>02}/{:>02} {:>02}:{:>02}:{:>02}]'.format(month, day, hour, minute, sec)\n",
    "    return output\n",
    "def __output_log(path, strs):\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w+') as f:\n",
    "            f.write(strs)\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(path, 'a+') as f:\n",
    "            f.write(strs)\n",
    "            f.close()\n",
    "print(now_str())\n",
    "print(torch.__version__)\n",
    "\n",
    "def reproject(params, vertices, distort=False):\n",
    "    R = params['R']\n",
    "    T = params['T']\n",
    "    fx = params['fx']\n",
    "    fy = params['fy']\n",
    "    cx = params['cx']\n",
    "    cy = params['cy']\n",
    "\n",
    "    E = np.array([\n",
    "        [R[0,0], R[0,1], R[0,2], T[0]], \n",
    "        [R[1,0], R[1,1], R[1,2], T[1]], \n",
    "        [R[2,0], R[2,1], R[2,2], T[2]], \n",
    "        [0, 0, 0, 1]]).astype('double')\n",
    "    \n",
    "    if distort:\n",
    "        k1 = params['k1']\n",
    "        k2 = params['k2']\n",
    "        k3 = params['k3']\n",
    "        p1 = params['p1']\n",
    "        p2 = params['p2']\n",
    "        \n",
    "    img_pts = []\n",
    "    for i in range(len(vertices)):\n",
    "        v = np.array(vertices[i])\n",
    "\n",
    "        # extrinsics\n",
    "        v4 = E.dot(np.array([v[0], v[1], v[2], 1]).astype('double'))\n",
    "        xp = v4[0] / v4[2]\n",
    "        yp = v4[1] / v4[2]\n",
    "\n",
    "        if distort:\n",
    "            # intrinsics\n",
    "            r2 = xp**2 + yp**2\n",
    "            ## radial\n",
    "            radial_dist = 1 + k1*(r2) + k2*(r2*r2) + k3*(r2*r2*r2)\n",
    "\n",
    "            ## tangential\n",
    "            tan_x = p2 * (r2 + 2.0 * xp * xp) + 2.0 * p1 * xp * yp\n",
    "            tan_y = p1 * (r2 + 2.0 * yp * yp) + 2.0 * p2 * xp * yp\n",
    "\n",
    "            xp = xp * radial_dist + tan_x\n",
    "            yp = yp * radial_dist + tan_y\n",
    "            \n",
    "        u = fx * xp + cx\n",
    "        v = fy * yp + cy\n",
    "        pr = 1\n",
    "        nr = 0\n",
    "        if (-4000*nr < u and u < pr*4000) and (-2160*nr < v and v < pr*2160):\n",
    "            img_pts.append(np.array([u, v]))\n",
    "    img_pts = np.array(img_pts)\n",
    "    return img_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "torch.cuda.current_device(): 0\n",
      "torch.cuda.get_device_name(0): GeForce RTX 2070 SUPER\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "torch.cuda.memory_reserved(): 0.00 Mb\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n",
      "----- torch.cuda.empty_cache() -----\n",
      "torch.cuda.memory_reserved(): 0.00 Mb\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n"
     ]
    }
   ],
   "source": [
    "print('torch.cuda.is_available():',torch.cuda.is_available())\n",
    "\n",
    "device_gpu = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(device_gpu)\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "print('torch.cuda.current_device():', torch.cuda.current_device())\n",
    "torch.cuda.ipc_collect()\n",
    "print('torch.cuda.get_device_name(0):',torch.cuda.get_device_name(0))\n",
    "\n",
    "# print('GPU memory stats ---------------------')\n",
    "# gpu_mem_stats = torch.cuda.memory_stats(device=device_gpu)\n",
    "# for k, v in gpu_mem_stats.items():\n",
    "#     print('  {}: {}'.format(k, v))\n",
    "\n",
    "print(torch.cuda.memory_summary(device=device_gpu, abbreviated=False))\n",
    "bytes_reserved = torch.cuda.memory_reserved()\n",
    "print('torch.cuda.memory_reserved(): {:,.2f} Mb'.format(bytes_reserved * 0.000001))\n",
    "# Returns the current GPU memory usage by \n",
    "# tensors in bytes for a given device\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "\n",
    "# Returns the current GPU memory managed by the\n",
    "# caching allocator in bytes for a given device\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "\n",
    "# Releases all unoccupied cached memory currently held by\n",
    "# the caching allocator so that those can be used in other\n",
    "# GPU application and visible in nvidia-smi\n",
    "print('----- torch.cuda.empty_cache() -----')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bytes_reserved = torch.cuda.memory_reserved()\n",
    "print('torch.cuda.memory_reserved(): {:,.2f} Mb'.format(bytes_reserved * 0.000001))\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class GaussianLayer(nn.Module):\n",
    "    def __init__(self, device, kernel_size, sigma, channels=4):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.conv = self._get_gaussian_conv2d(kernel_size, sigma)\n",
    "        self.conv.padding = int(self.kernel_size/2)\n",
    "        # Given groups=3, weight of size 3 1 3 3, expected input[1, 512, 512, 4] to have 3 channels, but got 512 channels instead\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x.shape) < 4:\n",
    "            x = x.unsqueeze(-1)\n",
    "        print('x:',x.shape)\n",
    "        print(self.conv.padding)\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "    \n",
    "    def _generate_gaussian_kernel(self, kernel_size, sigma, channels=4):\n",
    "        # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "        x_cord = torch.arange(kernel_size)\n",
    "        x_grid = x_cord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "        y_grid = x_grid.t()\n",
    "        xy_grid = torch.stack([x_grid, y_grid], dim=-1)\n",
    "\n",
    "        mean = (kernel_size - 1)/2.\n",
    "        variance = sigma**2.\n",
    "\n",
    "        # Calculate the 2-dimensional gaussian kernel which is\n",
    "        # the product of two gaussian distributions for two different\n",
    "        # variables (in this case called x and y)\n",
    "        gaussian_kernel = (1./(2.*math.pi*variance)) * torch.exp(-torch.sum((xy_grid - mean)**2., dim=-1) / (2*variance + 0.00001))\n",
    "        \n",
    "#         gaussian_kernel = torch.sum((xy_grid - mean)**2, dim=-1)\n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "        # Reshape to 2d depthwise convolutional weight\n",
    "        gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
    "        gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1, 1).to(self.device)\n",
    "        \n",
    "        return gaussian_kernel\n",
    "    \n",
    "    def _get_gaussian_conv2d(self, kernel_size, sigma, channels=4):\n",
    "        gaussian_filter = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size, stride=1, padding=int(kernel_size/2), groups=channels, bias=False).to(self.device)\n",
    "        gaussian_kernel = self._generate_gaussian_kernel(kernel_size=kernel_size, sigma=sigma, channels=channels)\n",
    "        gaussian_filter.weight.data = gaussian_kernel\n",
    "        gaussian_filter.weight.requires_grad = False\n",
    "        return gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device, **kwargs):\n",
    "        \"\"\"\n",
    "        image_size: a scalar. Only square image is supported in PyTorch3d\n",
    "        \"\"\"\n",
    "        stat_str = ''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "\n",
    "        self.image_size = kwargs.get('image_size', None)\n",
    "        \n",
    "        # set ref images: [0, 1] float32\n",
    "        image_refs = kwargs.get('image_refs', None)\n",
    "        self.image_refs = {}\n",
    "        n_images = 0\n",
    "        n_frames = 0\n",
    "        for img_name, img_list in image_refs.items():\n",
    "            n_frames += 1\n",
    "            n_images += len(img_list)\n",
    "            imgs_torch = torch.from_numpy(np.array(img_list).astype(np.float32)).to(self.device)\n",
    "            self.image_refs[img_name] = imgs_torch\n",
    "            \n",
    "        # set clean_plates:\n",
    "        clean_plates = kwargs.get('clean_plates', None)\n",
    "        if clean_plates is not None:\n",
    "            self.clean_plates = torch.from_numpy(np.array(clean_plates).astype(np.float32)).to(self.device)\n",
    "            print('clean_plates:', self.clean_plates.shape)\n",
    "        \n",
    "        # load texturemaps: [0.0, 1.0] float\n",
    "        texturemap_path = kwargs.get('texturemap_path', None)\n",
    "        texturemap = cv2.imread(texturemap_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0\n",
    "        texture_map_torch = torch.from_numpy(texturemap).unsqueeze(0).unsqueeze(-1).to(self.device)\n",
    "        self.texture_map = nn.Parameter(texture_map_torch, requires_grad=True)\n",
    "#         self.texture_map = texture_map_torch.clone()\n",
    "        \n",
    "        # batch_size\n",
    "        self.batch_dict = {'img_name': [], 'cam_idx': [], 'img_idx': []}\n",
    "        for cam_idx in range(16):\n",
    "            i = 0\n",
    "            for img_name in self.image_refs.keys():\n",
    "                self.batch_dict['img_name'].append(img_name)\n",
    "                self.batch_dict['cam_idx'].append(cam_idx)\n",
    "                self.batch_dict['img_idx'].append(i)\n",
    "                i += 1\n",
    "        \n",
    "        # init renderers\n",
    "        self.renderer = self._init_renderer()\n",
    "        \n",
    "        # camera batches\n",
    "        self.cam_params = kwargs.get('cam_params', None)\n",
    "        self.batch_size = kwargs.get('batch_size', None)\n",
    "        self.n_batch = kwargs.get('n_batch', None)\n",
    "        # self.cameras = self._init_cameras(self.cam_params)\n",
    "        self.cam_batches = self._init_camera_batches(self.cam_params, batch_dict=self.batch_dict, n_batch=self.n_batch, batch_size=self.batch_size)\n",
    "\n",
    "        # set mesh\n",
    "        mesh_paths = kwargs.get('mesh_paths', None)\n",
    "        self.meshes = self._load_meshes_list(self.device, mesh_paths=mesh_paths, texture_map=texture_map_torch)\n",
    "        # self.meshes, self.mesh_batches = self._load_mesh_batches(self.device, mesh_paths=mesh_paths, texture_map=texture_map_torch)\n",
    "        \n",
    "        # vertex deformations\n",
    "        verts = self.meshes[0].verts_packed()\n",
    "        dverts = torch.from_numpy(np.zeros(verts.shape, dtype=np.float32)).to(self.device)\n",
    "        self.deform_verts = nn.Parameter(dverts, requires_grad=True)\n",
    "        self.deformed_meshes = None\n",
    "        \n",
    "        \n",
    "    def deform_meshes(self):\n",
    "        self.deformed_meshes = [self.meshes[i].offset_verts(self.deform_verts) for i in range(len(self.meshes))]\n",
    "        \n",
    "    def forward(self, batch_idx, batch_size, deform_mesh: bool, learn_texturemap: bool, learn_deform: bool):\n",
    "        losses = {'total': 0.0, 'pixel': 0.0, 'normal': 0.0, 'laplacian': 0.0}\n",
    "        log = ''\n",
    "        t0 = time.time()\n",
    "        \n",
    "        self.deform_verts.requires_grad = learn_deform\n",
    "        self.texture_map.requires_grad = learn_texturemap\n",
    "        \n",
    "        t1 = time.time()\n",
    "        log += 'forward\\n'\n",
    "        log += ' - {:<10}: {:.3f}s\\n'.format('data prep', t1 - t0)\n",
    "        \n",
    "        # ==================================================================================== #\n",
    "        # minibatch training\n",
    "        i0 = batch_idx*batch_size\n",
    "        i1 = i0 + batch_size\n",
    "\n",
    "        cam_indices = self.batch_dict['cam_idx'][i0:i1]\n",
    "        mesh_indices = self.batch_dict['img_idx'][i0:i1]\n",
    "        img_names = self.batch_dict['img_name'][i0:i1]\n",
    "\n",
    "        t2 = time.time()\n",
    "        cam_batch = self.cam_batches[batch_idx]\n",
    "        meshes = [self.deformed_meshes[i] for i in mesh_indices]\n",
    "        meshes = join_meshes(meshes)\n",
    "        image_cur, log_render = self.renderer(meshes_world=meshes, cameras=cam_batch, texture_maps=self.texture_map)\n",
    "\n",
    "        # shape (batch_size, W, H)\n",
    "        bgs = self.clean_plates[i0:i1].squeeze()\n",
    "\n",
    "        # merge fg, bg\n",
    "        image_cur = self._merge_fg_bg(image_cur, bgs)\n",
    "        # image_cur = image_cur[..., 0]\n",
    "        # images_out = image_cur[...,:3]\n",
    "        images_out = image_cur\n",
    "\n",
    "        # [0, 0.1] float32\n",
    "        image_refs = torch.stack([self.image_refs[img_names[i]][cam_indices[i]] for i in range(self.batch_size)]).to(self.device)\n",
    "        # l_pixel = torch.mean(torch.abs(image_cur - image_refs))\n",
    "        l_pixel = torch.mean(torch.sum((image_cur - image_refs)**2))\n",
    "\n",
    "        t3 = time.time()\n",
    "        log += ' - [{}/{}] {:<10}: {:.3f}s\\n'.format(batch_idx+1, self.n_batch, 'batch render', t3 - t2)\n",
    "        log += '   ------------------------------------\\n'\n",
    "        log += log_render\n",
    "        log += '   ------------------------------------\\n'\n",
    "\n",
    "        l_normal = mesh_normal_consistency(meshes)\n",
    "        l_laplacian = mesh_laplacian_smoothing(meshes, method='uniform')\n",
    "        losses['normal'] += (l_normal / batch_size)\n",
    "        losses['laplacian'] += (l_laplacian / batch_size)\n",
    "        losses['pixel'] += (l_pixel / batch_size)\n",
    "        # ==================================================================================== #\n",
    "        \n",
    "        loss = 1.0*losses['pixel'] + 0.5*losses['normal'] + 0.5*losses['laplacian']\n",
    "#         loss = 1.0*losses['pixel']\n",
    "        \n",
    "        stat_str = self.get_gpu_stats(True)\n",
    "        return loss, images_out, self.texture_map, stat_str, losses, log\n",
    "    \n",
    "    def _merge_fg_bg(self, fg, bg):\n",
    "        \"\"\"\n",
    "        fg: mesh rendering. [N, W, H, 4]: [0, 1.0] float\n",
    "        bg: clean plate. [N, W, H]: [0, 255] uint8\n",
    "        \"\"\"\n",
    "        out = torch.where(fg[...,0] < 1.0, fg[...,0], bg)\n",
    "        if len(out.shape) < 3:\n",
    "            out = out.unsqueeze(0)\n",
    "        return out\n",
    "\n",
    "    def get_gpu_stats(self, output_str=True):\n",
    "        mb_reserved = torch.cuda.memory_reserved() * 0.000001\n",
    "        mb_alloc = torch.cuda.memory_allocated() * 0.000001\n",
    "        mb_alloc_max = torch.cuda.max_memory_allocated() * 0.000001\n",
    "        mb_cached = torch.cuda.memory_cached() * 0.000001\n",
    "        mb_cached_max = torch.cuda.max_memory_cached() * 0.000001\n",
    "        \n",
    "        if output_str:\n",
    "            return 'alloc={:,.0f}MB | cached={:,.0f}MB | reserved={:,.0f}MB'.format(mb_alloc, mb_cached, mb_reserved)\n",
    "        else:\n",
    "            return mb_alloc, mb_cached, mb_reserved\n",
    "        \n",
    "    def _load_mesh_batches(self, device, mesh_paths, texture_map):\n",
    "        meshes = load_objs_as_meshes(mesh_paths, universal_texturemap=texture_map.cpu(), device=device)\n",
    "        mesh_batches = self._convert_mesh_into_batches(meshes)\n",
    "        return meshes, mesh_batches\n",
    "    \n",
    "    def _load_meshes_list(self, device, mesh_paths, texture_map):\n",
    "        meshes_list = []\n",
    "        for path in mesh_paths:\n",
    "            meshes_list.append(load_objs_as_meshes([path], universal_texturemap=texture_map.cpu(), device=device))\n",
    "        return meshes_list\n",
    "    \n",
    "    \n",
    "    def _convert_mesh_into_batches(self, meshes):\n",
    "        mesh_batches = []\n",
    "        for batch_idx in range(self.n_batch):\n",
    "            i0 = batch_idx*self.batch_size\n",
    "            i1 = i0 + self.batch_size\n",
    "            meshes_join = []\n",
    "            for i in self.batch_dict['img_idx'][i0:i1]:\n",
    "                meshes_join.append(meshes[i])\n",
    "            mesh_batch = join_meshes(meshes_join, include_textures=True)\n",
    "            mesh_batches.append(mesh_batch)\n",
    "        return mesh_batches\n",
    "    \n",
    "    def save_parameters(self, out_path):\n",
    "        deform_verts = self.deform_verts.detach().cpu().numpy()\n",
    "        np.save(out_path, deform_verts)\n",
    "        print('Parameters saved:', out_path)\n",
    "        \n",
    "    def load_parameters(self, in_path):\n",
    "        self.deform_verts = nn.Parameter(torch.from_numpy(np.load(in_path)).to(self.device))\n",
    "        print('Parameters loaded: {}'.format(self.deform_verts.shape))\n",
    "        \n",
    "    def export_obj(self, out_dir, vt_path=None, fname_suffix=''):\n",
    "        vt_lines = []\n",
    "        f_lines = []\n",
    "        if vt_path is not None:\n",
    "            with open(vt_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for l in lines:\n",
    "                    v = l.split(' ')\n",
    "                    if v[0] == 'vt':\n",
    "                        vt_lines.append(l)\n",
    "                    elif v[0] == 'f':\n",
    "                        f_lines.append(l)\n",
    "\n",
    "        # normal_deforms = self.deform_verts * self.vert_normals\n",
    "        dverts = self.deform_verts\n",
    "        \n",
    "        out_name = 'learned_mesh'\n",
    "        for mesh_idx in range(len(self.meshes)):\n",
    "            out_path = out_dir + '/{}_{}{}.obj'.format(out_name, mesh_idx, fname_suffix)\n",
    "            deformed_mesh = self.meshes[mesh_idx].offset_verts(dverts)\n",
    "\n",
    "            verts = deformed_mesh.verts_packed()\n",
    "            faces = deformed_mesh.faces_packed()\n",
    "            vnormals = deformed_mesh.verts_normals_list()[0]\n",
    "            fnormals = deformed_mesh.faces_normals_list()[0]\n",
    "\n",
    "            assert(faces.shape[0] == fnormals.shape[0])\n",
    "            assert(vnormals.shape[0] == verts.shape[0])\n",
    "\n",
    "            with open(out_path, 'w+') as f:\n",
    "                f.write('# OBJ file created by Hyojoon Park.\\n')\n",
    "                f.write('###########################\\n')\n",
    "                f.write('# Vertices:       {}\\n'.format(verts.shape[0]))\n",
    "                f.write('# Vertex normals: {}\\n'.format(vnormals.shape[0]))\n",
    "                f.write('# Faces:          {}\\n'.format(faces.shape[0]))\n",
    "                f.write('###########################\\n')\n",
    "                f.write('mtllib learned_mesh.mtl\\n')\n",
    "                for i in range(verts.shape[0]):\n",
    "                    f.write('vn {} {} {}\\n'.format(vnormals[i][0], vnormals[i][1], vnormals[i][2]))\n",
    "                    f.write('v {} {} {}\\n'.format(verts[i][0], verts[i][1], verts[i][2]))\n",
    "                    \n",
    "                for vtl in vt_lines:\n",
    "                    f.write(vtl)\n",
    "                    \n",
    "                if len(f_lines) > 0:\n",
    "                    for fl in f_lines:\n",
    "                        f.write(fl)\n",
    "                else:\n",
    "                    for i in range(faces.shape[0]):\n",
    "                        f.write(\"f\")\n",
    "                        face = faces[i, :]\n",
    "                        for fi in range(face.shape[0]):\n",
    "                            f.write(' {0:.0f}//{0:.0f}//{0:.0f}'.format(face[fi] + 1, fnormals[fi] + 1))\n",
    "        #                     f.write(' {0:.0f}'.format(face[fi]))\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "            print('[{}/{}] Obj exported to: {}'.format(mesh_idx+1, len(self.meshes), out_path))\n",
    "        \n",
    "    def _init_renderer(self):\n",
    "        locations = torch.from_numpy(np.array([0, 0, 3000])).to(self.device)\n",
    "        a_diffuse = 0.0\n",
    "        a_ambient = 0.5\n",
    "        s = torch.from_numpy(np.zeros((1, 3)).astype(np.float32)).to(self.device)\n",
    "        d = torch.from_numpy(np.ones((1, 3)).astype(np.float32)*a_diffuse).to(self.device)\n",
    "        a = torch.from_numpy(np.ones((1, 3)).astype(np.float32)*a_ambient).to(self.device)\n",
    "        light = PointLights(device=self.device, location=[[1000, 1000, 1000]], specular_color=s, ambient_color=a, diffuse_color=d)\n",
    "        light.location = locations\n",
    "        light.specular_color = s\n",
    "        light.diffuse_color = d\n",
    "        light.ambient_color = a\n",
    "        \n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=self.image_size, \n",
    "            blur_radius=0.0, \n",
    "            faces_per_pixel=1, \n",
    "            bin_size = 0, # this setting controls whether naive or coarse-to-fine rasterization is used\n",
    "            max_faces_per_bin = None  # this setting is for coarse rasterization\n",
    "        )\n",
    "        renderer = MeshRenderer(\n",
    "                rasterizer=MeshRasterizer(\n",
    "                    cameras=None,\n",
    "                    raster_settings=raster_settings\n",
    "                ),\n",
    "                shader=TexturedSoftPhongShader(\n",
    "                    device=self.device, \n",
    "                    cameras=None,\n",
    "                    lights=light\n",
    "                )\n",
    "            )\n",
    "        return renderer\n",
    "    \n",
    "    def _init_cameras(self, cam_torch):\n",
    "        n_cams = len(cam_torch['T'])\n",
    "        Rs = torch.empty(n_cams, 3, 3)\n",
    "        Ts = torch.empty(n_cams, 3)\n",
    "        fls = torch.empty(n_cams, 2)\n",
    "        pps = torch.empty(n_cams, 2)\n",
    "        for cam_idx in range(n_cams):\n",
    "            fls[cam_idx] = cam_torch['fl'][cam_idx]\n",
    "            pps[cam_idx] = cam_torch['pp'][cam_idx]\n",
    "            Rs[cam_idx] = cam_torch['R'][cam_idx]\n",
    "            Ts[cam_idx] = cam_torch['T'][cam_idx]\n",
    "        cameras = SfMPerspectiveCameras(device=self.device, R=Rs, T=Ts, principal_point=pps, focal_length=fls)\n",
    "        return cameras\n",
    "    \n",
    "    def _init_camera_batches(self, cam_torch, batch_dict, n_batch, batch_size):\n",
    "        cams = []\n",
    "        for batch_idx in range(n_batch):\n",
    "            i0 = batch_idx*batch_size\n",
    "            i1 = i0 + batch_size\n",
    "            cam_indices = batch_dict['cam_idx'][i0:i1]\n",
    "            R = cam_torch['R'][cam_indices]\n",
    "            T = cam_torch['T'][cam_indices]\n",
    "            focal_length = cam_torch['fl'][cam_indices]\n",
    "            principal_point = cam_torch['pp'][cam_indices]\n",
    "            cameras = SfMPerspectiveCameras(device=self.device, R=R, T=T, principal_point=principal_point, focal_length=focal_length)\n",
    "            cams.append(cameras)\n",
    "        return cams\n",
    "    \n",
    "# batch_size = 2\n",
    "# n_batch = 16 // batch_size\n",
    "# model = Model(device_gpu, texturemap_path=texturemap_path, img_dir=img_dir, cam_params=cams_torch, image_refs=img_refs, mesh_paths=mesh_paths, image_size=image_size, clean_plates=clean_plates, batch_size=batch_size, n_batch=n_batch)\n",
    "\n",
    "# losses = []\n",
    "# images_rendered = torch.empty(n_batch*batch_size, model.image_size, model.image_size)\n",
    "\n",
    "# lr = 1.0\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# for batch_idx in range(n_batch):\n",
    "#     print('{}/{}'.format(batch_idx + 1, n_batch))\n",
    "#     i0 = batch_idx*batch_size\n",
    "#     i1 = i0 + batch_size\n",
    "    \n",
    "#     t0 = time.time()\n",
    "#     optimizer.zero_grad()\n",
    "#     model.deform_meshes()\n",
    "\n",
    "#     loss, imgs_rendered, tex_map, stat_gpu, loss_dict, _ = model(batch_idx, batch_size, deform_mesh=True, learn_texturemap=False, learn_deform=True)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     t1 = time.time()\n",
    "#     losses.append(loss)\n",
    "#     images_rendered[i0:i1] = imgs_rendered\n",
    "#     # model.save_parameters('./7_data/output/deform_verts.npy')\n",
    "#     # model.export_obj('./7_data/output/obj.obj')\n",
    "#     print('    forward:{:.2f}s'.format(t1-t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001s\n"
     ]
    }
   ],
   "source": [
    "def time_test(device, cam_params):\n",
    "    cams = []\n",
    "    batch_size = 16\n",
    "    n_batch = 16 // batch_size\n",
    "    t0 = time.time()\n",
    "\n",
    "    for batch_idx in range(n_batch):\n",
    "        i0 = batch_idx*batch_size\n",
    "        i1 = i0 + batch_size\n",
    "        R = cam_params['R'][i0:i1]\n",
    "        T = cam_params['T'][i0:i1]\n",
    "        focal_length = cam_params['fl'][i0:i1]\n",
    "        principal_point = cam_params['pp'][i0:i1]\n",
    "        cameras = SfMPerspectiveCameras(device=device, R=R, T=T, principal_point=principal_point, focal_length=focal_length)\n",
    "        cams.append(cameras)\n",
    "    t1 = time.time()\n",
    "    print('{:.3f}s'.format(t1-t0))\n",
    "time_test(device, cams_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mesh, camera, images, and feed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cameras(cam_path, device, actual_img_shape):\n",
    "    print('actual_img_shape:',actual_img_shape)\n",
    "    h = actual_img_shape[0]\n",
    "    w = actual_img_shape[1]\n",
    "    img_size = min(w, h)\n",
    "    \n",
    "    # load cameras\n",
    "    cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "\n",
    "    with open(cam_path, 'r') as f:\n",
    "        j = json.load(f)\n",
    "        camera_params = j['cam_params']\n",
    "\n",
    "    cameras = []\n",
    "    cam_params = []\n",
    "    Rs, Ts, focal_lengths, principal_points = [], [], [], []\n",
    "    for cam_idx, cam in enumerate(cams):\n",
    "        cam_param = camera_params[str(cam_idx)]\n",
    "        # for undistortion\n",
    "        fx = cam_param['fx']\n",
    "        fy = cam_param['fy']\n",
    "        cx = cam_param['cx']\n",
    "        cy = cam_param['cy']\n",
    "        k1 = cam_param['k1']\n",
    "        k2 = cam_param['k2']\n",
    "        k3 = cam_param['k3']\n",
    "        p1 = cam_param['p1']\n",
    "        p2 = cam_param['p2']\n",
    "        \n",
    "        rvec = np.float32(cam_param['rvec'])\n",
    "        T = np.float32(cam_param['tvec'])\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        Rs.append(R.T)\n",
    "        Ts.append(T)\n",
    "        \n",
    "        cx_corrected = cx*2/img_size - w/img_size\n",
    "        cy_corrected = cy*2/img_size - h/img_size\n",
    "        fx_corrected = fx*2/img_size\n",
    "        fy_corrected = fy*2/img_size\n",
    "        principal_point = np.array([cx_corrected, cy_corrected]).astype(np.float32)\n",
    "        focal_length = np.array([fx_corrected, fy_corrected]).astype(np.float32)\n",
    "#         principal_point = np.array([cx, cy]).astype(np.float32)\n",
    "#         focal_length = np.array([fx, fy]).astype(np.float32)\n",
    "        focal_lengths.append(focal_length)\n",
    "        principal_points.append(principal_point)\n",
    "\n",
    "        K = np.float32([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "        dist = np.float32([k1, k2, p1, p2, k3])\n",
    "        cam_params.append({'K': K, 'dist': dist, 'R': R, 'T': T, 'fx': fx, 'fy': fy, 'cx': cx, 'cy': cy})\n",
    "    \n",
    "    R_torch = torch.from_numpy(np.array(Rs).astype(np.float32))\n",
    "    T_torch = torch.from_numpy(np.array(Ts).astype(np.float32))\n",
    "    focal_length = torch.from_numpy(np.array(focal_lengths).astype(np.float32))\n",
    "    principal_point = torch.from_numpy(np.array(principal_points).astype(np.float32))\n",
    "    out_for_torch = {'R': R_torch, 'T': T_torch, 'fl': focal_length, 'pp': principal_point}\n",
    "    return cameras, cam_params, out_for_torch\n",
    "\n",
    "def load_images(img_dir, img_names):\n",
    "    image_refs_out = {}\n",
    "    crops_out = {}\n",
    "    \n",
    "    w = 2160 / 2\n",
    "    for img_name in img_names:\n",
    "        path = img_dir + '/{}/images/undistorted'.format(img_name)\n",
    "        img_paths = sorted(glob.glob(path + '/*.jpg'))\n",
    "        image_refs_undistort = []\n",
    "        for i, path in enumerate(img_paths):\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0\n",
    "            image_refs_undistort.append(img)\n",
    "\n",
    "        image_refs_cropped = []\n",
    "        for i in range(len(image_refs_undistort)):\n",
    "            image = image_refs_undistort[i]\n",
    "            cx = image.shape[1] / 2\n",
    "\n",
    "            image = image_refs_undistort[i]\n",
    "            img = image[:, int(cx-w):int(cx+w)]\n",
    "            img = cv2.resize(img, (image_size, image_size))\n",
    "            img = cv2.flip(img, -1)\n",
    "            image_refs_cropped.append(img)\n",
    "        image_refs_out[img_name] = image_refs_undistort\n",
    "        crops_out[img_name] = image_refs_cropped\n",
    "    return image_refs_out, crops_out\n",
    "                         \n",
    "def _undistort(img, cam_param):\n",
    "    # undistort a single image)\n",
    "    h, w = img.shape[:2]\n",
    "    # cv2.undistort(src, cameraMatrix, distCoeffs[, dst[, newCameraMatrix]]) â†’ dst\n",
    "    img = cv2.undistort(img, cam_param['K'], cam_param['dist'], None, None)\n",
    "    return img\n",
    "                         \n",
    "def load_clean_plates(img_dir, cam_params):\n",
    "    img_paths = sorted(glob.glob(img_dir + '/*.PNG'))\n",
    "    images0 = []\n",
    "    images_undistort = []\n",
    "    for i, path in enumerate(img_paths):\n",
    "        # img = imageio.imread(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0\n",
    "        img_undist = _undistort(img, cam_params[i])\n",
    "        images0.append(img)\n",
    "        images_undistort.append(img_undist)\n",
    "\n",
    "    w = 2160 / 2\n",
    "    clean_plates_cropped = []\n",
    "    for i in range(len(images_undistort)):\n",
    "        image = images_undistort[i]\n",
    "        cx = image.shape[1] / 2\n",
    "\n",
    "        image = images_undistort[i].astype(np.float32)\n",
    "        img = image[:, int(cx-w):int(cx+w)]\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = cv2.flip(img, -1)\n",
    "        # img = np.dstack([img, img, img])\n",
    "        clean_plates_cropped.append(img)\n",
    "    return images0, images_undistort, clean_plates_cropped "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "cam_path = r'D:\\CalibrationData\\CameraCalibration\\2019_12_13_Lada_Capture_k1k2k3p1p2\\FinalCamParams\\cam_params.json'\n",
    "mesh_dir = r'./9_data/input/vt_added'\n",
    "img_dir = './9_data/input'\n",
    "# img_names = ['03052', '03990', '04917', '06950']\n",
    "img_names = ['03052', '04917', '06950']\n",
    "# img_names = ['03052']\n",
    "clean_plate_dir = r'D:\\Pictures\\2019_12_13_Lada_Capture\\CleanPlates\\undistorted'\n",
    "texturemap_path = './9_data/output/200413_SingleVsMulti/multi_L1/texturemap_learned.png'\n",
    "\n",
    "texturemap_shape = (1080, 1080, 1)\n",
    "image_size = 512\n",
    "\n",
    "# input image size\n",
    "actual_img_shape = (2160, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "# cam_path = '9_data/input/cam_params.json'\n",
    "# mesh_dir = r'./9_data/input/vt_added'\n",
    "# img_dir = './9_data/input'\n",
    "# img_names = ['03052', '03990', '04917', '06950']\n",
    "# # img_names = ['03052', '03990']\n",
    "# # clean_plate_dir = r'D:\\200330_ToJanKeller\\data\\input\\clean_plate'\n",
    "\n",
    "# # number of batch will be automatically computed\n",
    "# batch_size = 2\n",
    "\n",
    "# texturemap_shape = (1080, 1080, 1)\n",
    "# image_size = 1080\n",
    "\n",
    "# # input image size\n",
    "# actual_img_shape = (2160, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_img_shape: (2160, 4000)\n",
      "Meshes:\n",
      "  ./9_data/input/vt_added\\03052Interpo_mm.obj\n",
      "  ./9_data/input/vt_added\\03990Interpo_mm.obj\n",
      "  ./9_data/input/vt_added\\04917Interpo_mm.obj\n",
      "  ./9_data/input/vt_added\\06950Interpo_mm.obj\n",
      "dict_keys(['03052', '03990', '04917', '06950'])\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "device = device_gpu\n",
    "cameras, cam_params, cams_torch = load_cameras(cam_path, device, actual_img_shape=actual_img_shape)\n",
    "img_refs_undistorted, img_refs = load_images(img_dir, img_names)\n",
    "\n",
    "mesh_paths_ = glob.glob(mesh_dir + '/*.obj')\n",
    "mesh_paths = []\n",
    "print('Meshes:')\n",
    "for p in mesh_paths_:\n",
    "    for img_name in img_names:\n",
    "        if img_name in p:\n",
    "            mesh_paths.append(p)\n",
    "            print(' ', p)\n",
    "print(img_refs_undistorted.keys())\n",
    "clean_plates_original, clean_plates_undistort, clean_plates = load_clean_plates(clean_plate_dir ,cam_params)\n",
    "print(clean_plates[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img_name = '03052'\n",
    "img1 = img_refs_undistorted[img_name][0]\n",
    "print('Image original =========')\n",
    "print(img1.shape, ',', np.max(img1), ',', img1.dtype)\n",
    "print('{:,.2f} Mb'.format(img1.nbytes * 0.000001))\n",
    "\n",
    "print()\n",
    "img2 = img_refs[img_name][0]\n",
    "print('Image cropped =========')\n",
    "print(img2.shape, ',', np.max(img2), ',', img2.dtype)\n",
    "print('{:,.2f} Mb'.format(img2.size * img2.itemsize * 0.000001))\n",
    "print()\n",
    "\n",
    "for img_name in img_names:\n",
    "    for i in range(16):\n",
    "        # target image\n",
    "        img1 = img_refs_undistorted[img_name][i]\n",
    "        img2 = img_refs[img_name][i]\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(50, 50))\n",
    "        ax[0].imshow(img1, cmap='gray')\n",
    "        ax[0].set_title('undistorted')\n",
    "        ax[1].imshow(img2, cmap='gray')\n",
    "        ax[1].set_title('undistorted & cropped')\n",
    "        ax[1].invert_yaxis()\n",
    "        ax[1].invert_xaxis()\n",
    "        plt.show()\n",
    "        break\n",
    "for i in range(16):\n",
    "    # clean plates\n",
    "    img1 = clean_plates_undistort[i]\n",
    "    img2 = clean_plates[i]\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(50, 50))\n",
    "    ax[0].imshow(img1, cmap='gray')\n",
    "    ax[0].set_title('undistorted')\n",
    "    ax[1].imshow(img2, cmap='gray')\n",
    "    ax[1].set_title('undistorted & cropped')\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].invert_xaxis()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_batch = 16 // batch_size\n",
    "model = Model(device_gpu, texturemap_path=texturemap_path, img_dir=img_dir, cam_params=cams_torch, image_refs=img_refs, mesh_paths=mesh_paths, image_size=image_size, clean_plates=clean_plates, batch_size=batch_size, n_batch=n_batch)\n",
    "texture_maps = model.texture_map\n",
    "print('texture_map: {:,.2f}=={:,.2f} Mb'.format(texture_maps.element_size() * texture_maps.nelement() * 0.000001, texture_maps.detach().cpu().numpy().nbytes*0.000001))\n",
    "texture_maps_np = texture_maps.detach().cpu().numpy()\n",
    "print('  {} {:,.2f}Mb {} {}'.format(texture_maps.shape, texture_maps_np.nbytes*0.000001, texture_maps.dtype, np.max(texture_maps_np)))\n",
    "img_name = list(model.image_refs.keys())[0]\n",
    "img = model.image_refs[img_name][0]\n",
    "print('ref image: {}, {:,.2f} Mb'.format(img.shape, img.element_size() * img.nelement() * 0.000001))\n",
    "plt.imshow(texture_maps_np.squeeze(), cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch3d mesh rendering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import image_grid\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "losses = []\n",
    "images_rendered = torch.empty(n_batch*batch_size, model.image_size, model.image_size)\n",
    "\n",
    "model.deform_meshes()\n",
    "for batch_idx in range(n_batch):\n",
    "    i0 = batch_idx*batch_size\n",
    "    i1 = i0 + batch_size\n",
    "    print(i0, '-', i1)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    loss, imgs_rendered, _, stat_gpu, _, _ = model(batch_idx, batch_size, deform_mesh=False, learn_texturemap=False, learn_deform=False)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    losses.append(loss.detach().cpu().data)\n",
    "    images_rendered[i0:i1] = imgs_rendered.detach().cpu()\n",
    "    del loss, imgs_rendered    \n",
    "    # model.save_parameters('./7_data/output/deform_verts.npy')\n",
    "    # model.export_obj('./7_data/output/obj.obj')\n",
    "    if batch_idx % 5 == 0:\n",
    "        print('[{:>2}/{}] forward:{:.2f}s | {}'.format(batch_idx + 1, n_batch, t1-t0, stat_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "# print(log)\n",
    "# mesh from pytorch3d\n",
    "i = 0\n",
    "img_mesh = images_rendered.squeeze().detach().cpu().numpy()\n",
    "print(images_rendered.shape)\n",
    "for batch_idx in range(model.n_batch):\n",
    "    fig, ax = plt.subplots(1, model.batch_size, figsize=(model.batch_size*5, 5))\n",
    "    if model.batch_size > 1:\n",
    "        ax = ax.ravel()\n",
    "        for n in range(model.batch_size):\n",
    "            img_mesh2 = img_mesh[i]\n",
    "            img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "            ax[n].set_title('batch[{}][{}] | i={}'.format(batch_idx, i, batch_idx*batch_size + i + 1))\n",
    "            ax[n].imshow(img_mesh2, cmap='gray', vmin=0, vmax=1)\n",
    "#             ax[n].imshow(img_mesh2)\n",
    "            i += 1\n",
    "    else:\n",
    "        img_mesh2 = img_mesh[i]\n",
    "        img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "        ax.set_title('batch[{}][{}] | i={}'.format(batch_idx, i, batch_idx*batch_size + i + 1))\n",
    "        ax.imshow(img_mesh2, cmap='gray', vmin=0, vmax=1)\n",
    "#         ax.imshow(img_mesh2)\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = model.image_refs['03052'][1].detach().squeeze().cpu().numpy()\n",
    "print(np.max(img1))\n",
    "plt.imshow(img1, cmap='gray', vmin=0, vmax=1.0)\n",
    "plt.show()\n",
    "img2 = images_rendered[0].detach().squeeze().cpu().numpy()\n",
    "print(np.max(img2))\n",
    "plt.imshow(img2, cmap='gray', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show rendered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mesh from pytorch3d\n",
    "i = 0\n",
    "img_mesh = images_rendered.squeeze().detach().cpu().numpy()\n",
    "for batch_idx in range(model.n_batch):\n",
    "    fig, ax = plt.subplots(1, model.batch_size, figsize=(model.batch_size*5, 5))\n",
    "    if model.batch_size > 1:\n",
    "        ax = ax.ravel()\n",
    "        for n in range(model.batch_size):\n",
    "            img_mesh2 = img_mesh[i]\n",
    "            img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "            ax[n].set_title('batch[{}][{}] | i={}'.format(batch_idx, i, batch_idx*batch_size + i + 1))\n",
    "            ax[n].imshow(img_mesh2, cmap='gray')\n",
    "            i += 1\n",
    "    else:\n",
    "        img_mesh2 = img_mesh[i]\n",
    "        img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "        ax.set_title('batch[{}][{}] | i={}'.format(batch_idx, i, batch_idx*batch_size + i + 1))\n",
    "        ax.imshow(img_mesh2, cmap='gray')\n",
    "        i += 1\n",
    "    plt.show()\n",
    "print(stats_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add clean plate background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_fg_bg(fg, bg):\n",
    "    \"\"\"\n",
    "    fg: mesh rendering. [W, H, 4]: [0, 1.0] float\n",
    "    bg: clean plate. [W, H]: [0, 255] uint8\n",
    "    \"\"\"\n",
    "    max_pixel = np.max(fg)\n",
    "    out = np.where(fg[...,0] < max_pixel, 255*fg[...,0], bg)\n",
    "    return out\n",
    "    \n",
    "img_idx = 0\n",
    "cp = clean_plates[img_idx]\n",
    "img = img_mesh[img_idx]\n",
    "img2 = merge_fg_bg(img, cp)\n",
    "plt.imshow(img2, cmap='gray', vmin=0, vmax=255)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reprojections of obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_points = {}\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(len(model.meshes)):\n",
    "    mesh_vertices = model.meshes[i].verts_packed().cpu()\n",
    "    \n",
    "    pts = []\n",
    "    for cam_idx in range(16):\n",
    "        params = cam_params[cam_idx]\n",
    "        p = reproject(params, mesh_vertices, distort=False)\n",
    "        pts.append(p)\n",
    "    \n",
    "    img_name = img_names[i]\n",
    "    mesh_points[img_name] = pts\n",
    "t1 = time.time()\n",
    "print('{:.2f}s'.format(t1-t0))\n",
    "print(len(pts))\n",
    "print(len(mesh_points))\n",
    "del mesh_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "bd = model.batch_dict\n",
    "img_idx = bd['img_idx']\n",
    "for i in range(len(img_idx)):\n",
    "    cam_idx = bd['cam_idx'][i]\n",
    "    img_name = bd['img_name'][i]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # bg\n",
    "    img_bg = img_refs[img_name][cam_idx]\n",
    "    img_bg = cv2.flip(img_bg, -1)\n",
    "    plt.imshow(img_bg, cmap='gray')\n",
    "    \n",
    "    # mesh from pytorch3d\n",
    "    img_mesh = images_rendered[i].squeeze().detach().cpu().numpy()\n",
    "    img_mesh2 = img_mesh\n",
    "    img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "    plt.imshow(img_mesh2, alpha=0.5, cmap='gray')\n",
    "\n",
    "    pts = mesh_points[img_name][cam_idx]\n",
    "    pts_small_x = (pts[:, 0] - (4000-2160)*0.5) * image_size/2160\n",
    "    pts_small_y = pts[:, 1] * image_size/2160\n",
    "    pts_small = np.stack([pts_small_x, pts_small_y]).T\n",
    "    pts_center = np.mean(pts_small, axis=0)\n",
    "    plt.scatter(pts_small[:, 0], pts_small[:, 1], c='b', s=0.1)\n",
    "    plt.title('Camera {}'.format(i))\n",
    "\n",
    "    # plot centers\n",
    "    plt.scatter(pts_center[0], pts_center[1], c='r')\n",
    "\n",
    "    if i == 0:\n",
    "        print('reference image:', np.max(img_bg), img_bg.dtype, img_bg.shape)\n",
    "        print('rendered pytorch image :', np.max(img_mesh), img_mesh.dtype, img_mesh.shape, ', {:,.2f} Mb'.format(img_mesh.nbytes * 0.000001), np.max(img_mesh))\n",
    "        print('rendered pytorch image2:', np.max(img_mesh2), img_mesh2.dtype, img_mesh2.shape, ', {:,.2f} Mb'.format(img_mesh2.nbytes * 0.000001), np.max(img_mesh2))\n",
    "    plt.show()\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_LR(e, lr, losses, images, imgR, out_path):\n",
    "    cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "    img_meshes = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i].detach().squeeze(0).cpu().numpy()\n",
    "        img_mesh = np.clip(cv2.flip(img, -1), a_min=0.0, a_max=1.0)\n",
    "        img_meshes.append(img_mesh)\n",
    "        \n",
    "    fig = plt.figure(figsize=(18, 3), tight_layout=True)\n",
    "    \n",
    "    gs = fig.add_gridspec(2, 12)\n",
    "    for r in range(2):\n",
    "        for c in range(8):\n",
    "            i = r*8 + c\n",
    "            ax = fig.add_subplot(gs[r, c])\n",
    "            ax.set_title('{}'.format(cams[i]))\n",
    "            ax.imshow(img_meshes[i], cmap='gray')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    ax = fig.add_subplot(gs[:, 8:10])\n",
    "    ax.plot(losses)\n",
    "    ax.set_title('loss={:.8f}'.format(losses[-1]))\n",
    "    \n",
    "    ax = fig.add_subplot(gs[:, 10:12])\n",
    "    imgR2 = imgR.squeeze().detach().cpu().numpy()\n",
    "    imgR2 = np.clip(imgR2, a_min=0.0, a_max=1.0)\n",
    "    ax.imshow(imgR2, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax.set_title('Learned Texturemap')\n",
    "    \n",
    "    plt.suptitle('Epoch: {:<10}  lr: {:<.4f}'.format(e, lr))\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close('all')\n",
    "    \n",
    "    saved_img = imageio.imread(save_path)\n",
    "    return saved_img\n",
    "\n",
    "def visualize2(e, lr, losses, losses_dict, image1, image2, image3, out_path):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(24, 6), tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    ax[0].plot(losses)\n",
    "    ax[0].set_title('Epoch={}, lr={:.4f}, loss={:.4f}, pixel_loss={:.4f}'.format(e, lr, losses[-1], losses_dict['pixel']))\n",
    "    \n",
    "    ax[1].imshow(image1, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].invert_xaxis()\n",
    "    ax[1].set_title('Current image')\n",
    "    \n",
    "    ax[2].imshow(image2, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].invert_xaxis()\n",
    "    ax[2].set_title('Target image')\n",
    "\n",
    "    ax[3].imshow(image3, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax[3].set_title('Learned texturemap')\n",
    "\n",
    "    \n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close('all')\n",
    "    \n",
    "    saved_img = imageio.imread(save_path)\n",
    "    return saved_img\n",
    "    \n",
    "def get_gpu_stats(output_str=True):\n",
    "    mb_reserved = torch.cuda.memory_reserved() * 0.000001\n",
    "    mb_alloc = torch.cuda.memory_allocated() * 0.000001\n",
    "    mb_cached = torch.cuda.memory_cached() * 0.000001\n",
    "    if output_str:\n",
    "        return 'alloc={:,.0f}MB | cached={:,.0f}MB | reserved={:,.0f}MB'.format(mb_alloc, mb_cached, mb_reserved)\n",
    "    else:\n",
    "        return mb_alloc, mb_cached, mb_reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init mesh & texturemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- torch.cuda.empty_cache() -----\n",
      "torch.cuda.memory_allocated(): 111.61 Mb\n",
      "torch.cuda.memory_cached(): 165.68 Mb\n",
      "clean_plates: torch.Size([16, 512, 512])\n",
      "[1/4] Obj exported to: ./10_data/output/learned_mesh_0_init.obj\n",
      "[2/4] Obj exported to: ./10_data/output/learned_mesh_1_init.obj\n",
      "[3/4] Obj exported to: ./10_data/output/learned_mesh_2_init.obj\n",
      "[4/4] Obj exported to: ./10_data/output/learned_mesh_3_init.obj\n"
     ]
    }
   ],
   "source": [
    "# del model\n",
    "print('----- torch.cuda.empty_cache() -----')\n",
    "torch.cuda.empty_cache()\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "batch_size = 2\n",
    "n_batch = 16 // batch_size\n",
    "model = Model(device_gpu, texturemap_path=texturemap_path, img_dir=img_dir, cam_params=cams_torch, image_refs=img_refs, mesh_paths=mesh_paths, image_size=image_size, clean_plates=clean_plates, batch_size=batch_size, n_batch=n_batch)\n",
    "model.export_obj('./10_data/output', vt_path='./9_data/input/vt_added/03052Interpo_mm.obj', fname_suffix='_init')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log output: ./10_data/output/log_20200415_15h28m.txt\n",
      "Model parameters:\n",
      "  texture_map, requires_grad=True\n",
      "  deform_verts, requires_grad=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-d6449abcddb7>:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  loop = tqdm_notebook(range(1000000000))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd58eae73db44dda577579bceb43d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    12: reducing learning rate of group 0 to 7.5000e-01.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-d6449abcddb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mlatest_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_dict'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstat_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeform_mesh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_texturemap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_deform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mlatest_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mlatest_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_dict'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch3d\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-16003ce05340>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch_idx, batch_size, deform_mesh, learn_texturemap, learn_deform)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mlog\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'   ------------------------------------\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0ml_normal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmesh_normal_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeshes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0ml_laplacian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmesh_laplacian_smoothing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeshes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml_normal\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\1_projects\\200323_pytorch3dstart\\pytorch3d\\loss\\mesh_normal_consistency.py\u001b[0m in \u001b[0;36mmesh_normal_consistency\u001b[1;34m(meshes)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# two of the following cross products are zeros as they are cross product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m# with either (v1-v0)x(v1-v0) or (v1-v0)x(v0-v0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0mn_temp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverts_packed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvert_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mn_temp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverts_packed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvert_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mn_temp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverts_packed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvert_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out_dir = './10_data/output'\n",
    "save_path = out_dir + '/plot.png'\n",
    "\n",
    "# filename_output = './4_data/output/4b/out.gif'\n",
    "# writer = imageio.get_writer(filename_output, mode='I', duration=0.3)\n",
    "now = datetime.now()\n",
    "hour = str(now.hour)\n",
    "minute = str(now.minute)\n",
    "date_str = '{}{:>02}{:>02}_{:>02}h{:>02}m'.format(now.year, now.month, now.day, hour, minute)\n",
    "log_path = out_dir + '/log_{}.txt'.format(date_str)\n",
    "__output_log(log_path, '========== {} Start ==========================\\n'.format(date_str))\n",
    "print('Log output: {}'.format(log_path))\n",
    "\n",
    "lr = 1.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.75, patience=10, verbose=True)\n",
    "\n",
    "print('Model parameters:')\n",
    "for name, param in model.named_parameters():\n",
    "    print('  {}, requires_grad={}'.format(name, param.requires_grad))\n",
    "        \n",
    "loop = tqdm_notebook(range(1000000000))\n",
    "\n",
    "bd = model.batch_dict\n",
    "save_idx = 0\n",
    "losses = []\n",
    "loss_belows, loss_aboves = 0, 0\n",
    "losses_below, losses_above = [], []\n",
    "latest_states = {'loss': 0.0}\n",
    "stat_str = ''\n",
    "for e in loop:\n",
    "    output_texels = (e % 10 == 0)\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    batch_size = model.batch_size\n",
    "    images = torch.empty(model.n_batch*model.batch_size, model.image_size, model.image_size)\n",
    "    \n",
    "    # ========================================================================================================================================= #\n",
    "    for batch_idx in range(model.n_batch):\n",
    "        i0 = batch_idx*batch_size\n",
    "        i1 = i0 + batch_size\n",
    "        \n",
    "        t0 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        t1 = time.time()\n",
    "        model.deform_meshes()\n",
    "\n",
    "        if output_texels:\n",
    "            l, imgs, texels, _, loss_dict, log = model(batch_idx, batch_size, deform_mesh=True, learn_texturemap=False, learn_deform=True)\n",
    "            images[i0:i1] = imgs\n",
    "            \n",
    "            latest_states['loss'] += loss\n",
    "            latest_states['images'] = images.clone()\n",
    "            latest_states['texels'] = texels.clone()\n",
    "            latest_states['loss_dict'] = loss_dict\n",
    "        else:\n",
    "            l, _, _, stat_gpu, loss_dict, log = model(batch_idx, batch_size, deform_mesh=True, learn_texturemap=False, learn_deform=True)\n",
    "            latest_states['loss'] += loss\n",
    "            latest_states['loss_dict'] = loss_dict\n",
    "        if e > 0 and e % 50 == 0:\n",
    "            model.save_parameters('./10_data/output/deform_verts.npy')\n",
    "            model.export_obj('./10_data/output', vt_path='./9_data/input/vt_added/03052Interpo_mm.obj')\n",
    "        loss += l.data\n",
    "        t2 = time.time()\n",
    "        l.backward()\n",
    "        t3 = time.time()\n",
    "        optimizer.step()\n",
    "        t4 = time.time()\n",
    "        scheduler.step(l)\n",
    "    # ========================================================================================================================================= #\n",
    "    \n",
    "    losses.append(loss)\n",
    "    losses_below.append(loss_belows)\n",
    "    losses_above.append(loss_aboves)\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    loop.set_description('[{}/{}] lr={:.4f}, loss={:.6f}'.format(e, len(loop), lr, loss))\n",
    "\n",
    "    if output_texels:\n",
    "        # Save outputs to create a GIF. \n",
    "        t10 = time.time()\n",
    "\n",
    "        img_idx = bd['img_idx'][save_idx]\n",
    "        cam_idx = bd['cam_idx'][save_idx]\n",
    "        img_name = bd['img_name'][save_idx]\n",
    "        image1 = images.squeeze().detach().cpu().numpy()[save_idx]\n",
    "        image2 = img_refs[img_name][cam_idx]\n",
    "        image3 = texels.detach().squeeze().cpu().numpy()\n",
    "        saved_img = visualize2(e, lr, losses, loss_dict, image1, image2, image3, save_path)\n",
    "        # image_out = visualize_LR(e, lr, losses, images, texels, save_path)\n",
    "        plt.figure()\n",
    "        plt.imshow(saved_img)\n",
    "        plt.title(\"iter: %d, lr: %0.4f, loss: %0.8f\" % (e, lr, loss))\n",
    "        plt.grid(\"off\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "\n",
    "        texels_np = model.texture_map.detach().cpu().numpy()\n",
    "        np.save(out_dir + '/texturemap.npy', texels_np)\n",
    "        del texels_np\n",
    "\n",
    "        texturemap_out = (255.0*np.clip(model.texture_map.detach().squeeze().cpu().numpy(), a_min=0, a_max=1.0)).astype(np.uint8)\n",
    "        im = Image.fromarray(texturemap_out)\n",
    "        im.save(out_dir + '/texturemap_learned.png', dpi=(600, 600))\n",
    "        t11 = time.time()\n",
    "\n",
    "#             image_out = image_out / 255.0\n",
    "#             image_out = np.clip(image_out, 0, 1)\n",
    "#             image_out = img_as_ubyte(image_out)\n",
    "#             writer.append_data(image_out)\n",
    "        t12 = time.time()\n",
    "\n",
    "        __output_log(log_path, '{:03} | plot({:.2f}s) | gif({:.2f}s)\\n'.format(e+1, t11-t10, t12-t11))\n",
    "#             stat_str += '  {:<21}: {}\\n'.format('plotting', get_gpu_stats())\n",
    "        save_idx += 1\n",
    "        if save_idx >= len(bd['img_idx']):\n",
    "            save_idx = 0\n",
    "    # execution time\n",
    "    t01 = t1-t0\n",
    "    t12 = t2-t1\n",
    "    t23 = t3-t2\n",
    "    t34 = t4-t3\n",
    "    t5 = time.time()\n",
    "\n",
    "    mb_alloc = torch.cuda.memory_allocated() * 0.000001\n",
    "    mb_cached = torch.cuda.memory_cached() * 0.000001\n",
    "    mb_alloc_max = torch.cuda.max_memory_allocated() * 0.000001\n",
    "    mb_cached_max = torch.cuda.max_memory_cached() * 0.000001\n",
    "    now = datetime.now()\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    second = str(now.second)\n",
    "    now_str = '{:>02}:{:>02}:{:>02}'.format(hour, minute, second)\n",
    "    __output_log(log_path, '{} | {:03} | {:.2f}s | lr={:.8f} | loss={:.6f} | pixel_l={:.4f} | normal_l={:.4f} | lap_l={:.4f} | zero_grad({:.2f}s) | forward({:.2f}s) | backward({:.2f}s) | step({:.2f}s) | GPU_alloc({:,.2f}Mb), max({:,.2f}Mb) | GPU_cache({:,.2f}Mb), max({:,.2f}Mb)\\n'.format(now_str, e+1, t5-t0, lr, loss, loss_dict['pixel'], loss_dict['normal'], loss_dict['laplacian'], t01, t12, t23, t34, mb_alloc, mb_alloc_max, mb_cached, mb_cached_max))\n",
    "\n",
    "    # clean up\n",
    "    if output_texels:\n",
    "        del loss, images, texels\n",
    "    else:\n",
    "        del loss\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    __output_log(log_path, '{}'.format(stat_str))\n",
    "    if e > 100:\n",
    "        break\n",
    "            \n",
    "torch.cuda.empty_cache()\n",
    "# loss, images, texels, stat_str = model()\n",
    "loss, images, texels = latest_states['loss'], latest_states['images'], latest_states['texels']\n",
    "print(stat_str)\n",
    "\n",
    "save_dir = out_dir\n",
    "for i in range(len(images)):\n",
    "    print(' ', i+1, end='')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12), tight_layout=True)\n",
    "    img = images[i].detach().cpu().numpy()\n",
    "    ax[0].imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[1].imshow(img_refs[i], cmap='gray')\n",
    "    ax[1].invert_yaxis()\n",
    "    plt.savefig(save_dir + '/compare_cam{}.png'.format(i+1), dpi=300)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dverts = model.deform_verts\n",
    "dverts = dverts.detach().cpu().numpy()\n",
    "dverts_mag = np.linalg.norm(dverts, axis = 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(dverts_mag)), dverts_mag)\n",
    "plt.ylabel('change in magnitude [mm]')\n",
    "plt.xlabel('vertex index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# # plt.plot(losses, 'k')\n",
    "# plt.plot(losses_above, 'r')\n",
    "# plt.plot(losses_below, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# loss, images, texels, stat_str = model()\n",
    "loss, images, texels = latest_states['loss'], latest_states['images'], latest_states['texels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texture_maps = texels.detach().squeeze().cpu()\n",
    "td = texels.detach().cpu()\n",
    "print(td.shape)\n",
    "print(torch.min(td),',', torch.max(td))\n",
    "\n",
    "td_a = torch.clamp(-1.0*texture_maps, min=0.0)\n",
    "print('n_above:', torch.sum(td_a > 0.0))\n",
    "td_b = torch.clamp(texture_maps, min=1.0) - torch.ones(texture_maps.shape)\n",
    "print('n_below:', torch.sum(td_b > 1.0))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(td_a, vmin=0, vmax=1.0)\n",
    "ax[0].set_title('Pixels > 1.0')\n",
    "ax[1].imshow(td_b, vmin=0, vmax=1.0)\n",
    "ax[1].set_title('Pixels < 0.0')\n",
    "plt.figure()\n",
    "plt.imshow(td.clone().squeeze().numpy(), cmap='gray', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save rendered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_dir = out_dir\n",
    "            \n",
    "img_idx = bd['img_idx']\n",
    "cam_idx = bd['cam_idx']\n",
    "img_name = bd['img_name']\n",
    "for n in range(len(img_idx)):\n",
    "    cam_i = cam_idx[n]\n",
    "    name = img_name[n]\n",
    "    print(' ', n+1, end='')\n",
    "    if n > 0 and n % 16 == 0:\n",
    "        print()\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12), tight_layout=True)\n",
    "    img = images[n].detach().cpu().numpy()\n",
    "    ax[0].imshow(img, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].invert_xaxis()\n",
    "    ax[1].imshow(img_refs[name][cam_i], cmap='gray')\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].invert_xaxis()\n",
    "    plt.savefig(save_dir + '/compare_cam{}.png'.format(n+1), dpi=300)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(16, 1, figsize=(15, 140))\n",
    "ax = ax.ravel()\n",
    "for i in range(len(ax)):\n",
    "    img_mesh = images_rendered[i]\n",
    "    img_mesh = cv2.flip(img_mesh, -1)\n",
    "    img_bg = image_refs[i]\n",
    "    img_bg = cv2.flip(img_bg, -1)\n",
    "    ax[i].imshow(img_bg)\n",
    "\n",
    "    img_mesh_large = np.zeros(img_bg.shape)\n",
    "    img_mesh_padded = cv2.copyMakeBorder(img_mesh, 0, 0, int((4000-2160)/2), int((4000-2160)/2), 0, None, [0, 0, 0])\n",
    "    ax[i].imshow(img_mesh, alpha=0.5)\n",
    "    \n",
    "    pts = mesh_points[i]\n",
    "    pts_small_x = (pts[:, 0] - (4000-2160)*0.5) * rendered_image_size/2160\n",
    "    pts_small_y = pts[:, 1] * rendered_image_size/2160\n",
    "    pts_small = np.stack([pts_small_x, pts_small_y]).T\n",
    "    pts_center = np.mean(pts_small, axis=0)\n",
    "#     ax[i].scatter(pts[:, 0], pts[:, 1], c='r', s=0.1)\n",
    "#     ax[i].scatter(pts_small[:, 0], pts_small[:, 1], c='r', s=0.01)\n",
    "    ax[i].set_title('Camera {}'.format(cams[i]))\n",
    "    \n",
    "    # plot centers\n",
    "    ax[i].scatter(pts_center[0], pts_center[1], c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, meshes, image_refs, renderers, texture_maps):\n",
    "        super().__init__()\n",
    "        self.meshes = meshes\n",
    "        self.device = meshes.device\n",
    "        self.renderers = renderers\n",
    "        self.register_buffer('image_refs', image_refs)\n",
    "\n",
    "        self.texture_maps = nn.Parameter(texture_maps.to(meshes.device), requires_grad=True)\n",
    "        \n",
    "    def forward(self):\n",
    "        loss = 0\n",
    "        images = []\n",
    "        for i in range(len(self.renderers)):\n",
    "            image = self.renderers[i](meshes_world=self.meshes, texture_maps=self.texture_maps)\n",
    "            loss_i = torch.mean((image.squeeze()[..., :3] - self.image_refs[i]) ** 2)\n",
    "            images.append(image)\n",
    "            loss = loss + loss_i\n",
    "        loss /= len(self.renderers)\n",
    "\n",
    "        return loss, images, self.texture_maps.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(model.texture_maps.detach().cpu().numpy()[0, :, :, :])\n",
    "plt.savefig('./4_data/output/4b/texturemap_learned.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1, 1), requires_grad=True)\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    print(prof)\n",
    "    for _ in range(100):  # any normal python code, really!\n",
    "        y = x ** 2\n",
    "        y.backward()\n",
    "# NOTE: some columns were removed for brevity\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_stats(device=device_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=device_gpu, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_stats = torch.cuda.memory_stats(device=device_gpu)\n",
    "for k, v in mem_stats.items():\n",
    "    print('{}: {}'.format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.max_memory_allocated(device=device_gpu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
