{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:96% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/15 00:54:59]\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "import imageio\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "from pytorch3d.loss import (\n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "# Util function for loading meshes\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "import math\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Meshes, Textures\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    OpenGLPerspectiveCameras, \n",
    "    SfMPerspectiveCameras,\n",
    "    SfMOrthographicCameras,\n",
    "    PointLights, \n",
    "    DirectionalLights,\n",
    "    Materials, \n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer,  \n",
    "    TexturedSoftPhongShader,\n",
    "    SoftSilhouetteShader,\n",
    "    look_at_rotation,\n",
    "    HardFlatShader\n",
    ")\n",
    "\n",
    "# add path for demo utils functions \n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "sys.path.append(os.path.abspath(''))\n",
    "\n",
    "from datetime import datetime\n",
    "def now_str():\n",
    "    now = datetime.now()\n",
    "    month = str(now.month)\n",
    "    day = str(now.day)\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    sec = str(now.second)\n",
    "    \n",
    "    output = '[{:>02}/{:>02} {:>02}:{:>02}:{:>02}]'.format(month, day, hour, minute, sec)\n",
    "    return output\n",
    "def __output_log(path, strs):\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w+') as f:\n",
    "            f.write(strs)\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(path, 'a+') as f:\n",
    "            f.write(strs)\n",
    "            f.close()\n",
    "print(now_str())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reproject(params, vertices, distort=False):\n",
    "    R = params['R']\n",
    "    T = params['T']\n",
    "    fx = params['fx']\n",
    "    fy = params['fy']\n",
    "    cx = params['cx']\n",
    "    cy = params['cy']\n",
    "\n",
    "    E = np.array([\n",
    "        [R[0,0], R[0,1], R[0,2], T[0]], \n",
    "        [R[1,0], R[1,1], R[1,2], T[1]], \n",
    "        [R[2,0], R[2,1], R[2,2], T[2]], \n",
    "        [0, 0, 0, 1]]).astype('double')\n",
    "    \n",
    "    if distort:\n",
    "        k1 = params['k1']\n",
    "        k2 = params['k2']\n",
    "        k3 = params['k3']\n",
    "        p1 = params['p1']\n",
    "        p2 = params['p2']\n",
    "        \n",
    "    img_pts = []\n",
    "    for i in range(len(vertices)):\n",
    "        v = np.array(vertices[i])\n",
    "\n",
    "        # extrinsics\n",
    "        v4 = E.dot(np.array([v[0], v[1], v[2], 1]).astype('double'))\n",
    "        xp = v4[0] / v4[2]\n",
    "        yp = v4[1] / v4[2]\n",
    "\n",
    "        if distort:\n",
    "            # intrinsics\n",
    "            r2 = xp**2 + yp**2\n",
    "            ## radial\n",
    "            radial_dist = 1 + k1*(r2) + k2*(r2*r2) + k3*(r2*r2*r2)\n",
    "\n",
    "            ## tangential\n",
    "            tan_x = p2 * (r2 + 2.0 * xp * xp) + 2.0 * p1 * xp * yp\n",
    "            tan_y = p1 * (r2 + 2.0 * yp * yp) + 2.0 * p2 * xp * yp\n",
    "\n",
    "            xp = xp * radial_dist + tan_x\n",
    "            yp = yp * radial_dist + tan_y\n",
    "            \n",
    "        u = fx * xp + cx\n",
    "        v = fy * yp + cy\n",
    "        pr = 1\n",
    "        nr = 0\n",
    "        if (-4000*nr < u and u < pr*4000) and (-2160*nr < v and v < pr*2160):\n",
    "            img_pts.append(np.array([u, v]))\n",
    "    img_pts = np.array(img_pts)\n",
    "    return img_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# torch.cuda.set_device(device)\n",
    "device = torch.device(\"cpu\")\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "torch.cuda.current_device(): 0\n",
      "torch.cuda.get_device_name(0): GeForce RTX 2070 SUPER\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "torch.cuda.memory_reserved(): 0.00 Mb\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n",
      "----- torch.cuda.empty_cache() -----\n",
      "torch.cuda.memory_reserved(): 0.00 Mb\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n"
     ]
    }
   ],
   "source": [
    "print('torch.cuda.is_available():',torch.cuda.is_available())\n",
    "\n",
    "device_gpu = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(device_gpu)\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "print('torch.cuda.current_device():', torch.cuda.current_device())\n",
    "torch.cuda.ipc_collect()\n",
    "print('torch.cuda.get_device_name(0):',torch.cuda.get_device_name(0))\n",
    "\n",
    "# print('GPU memory stats ---------------------')\n",
    "# gpu_mem_stats = torch.cuda.memory_stats(device=device_gpu)\n",
    "# for k, v in gpu_mem_stats.items():\n",
    "#     print('  {}: {}'.format(k, v))\n",
    "\n",
    "print(torch.cuda.memory_summary(device=device_gpu, abbreviated=False))\n",
    "bytes_reserved = torch.cuda.memory_reserved()\n",
    "print('torch.cuda.memory_reserved(): {:,.2f} Mb'.format(bytes_reserved * 0.000001))\n",
    "# Returns the current GPU memory usage by \n",
    "# tensors in bytes for a given device\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "\n",
    "# Returns the current GPU memory managed by the\n",
    "# caching allocator in bytes for a given device\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "\n",
    "# Releases all unoccupied cached memory currently held by\n",
    "# the caching allocator so that those can be used in other\n",
    "# GPU application and visible in nvidia-smi\n",
    "print('----- torch.cuda.empty_cache() -----')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bytes_reserved = torch.cuda.memory_reserved()\n",
    "print('torch.cuda.memory_reserved(): {:,.2f} Mb'.format(bytes_reserved * 0.000001))\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device, **kwargs):\n",
    "        \"\"\"\n",
    "        image_size: a scalar. Only square image is supported in PyTorch3d\n",
    "        \"\"\"\n",
    "        stat_str = ''\n",
    "        \n",
    "        super().__init__()\n",
    "#         stat_str += '  super().__init__(): {}\\n'.format(self.get_gpu_stats(True))\n",
    "        self.device = device\n",
    "#         stat_str += '  self.device: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        self.cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "\n",
    "        self.image_size = kwargs.get('image_size', None)\n",
    "#         stat_str += '  self.image_size: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        \n",
    "        # set ref images: [0, 255] uint8\n",
    "        image_refs = kwargs.get('image_refs', None)\n",
    "        self.image_refs = torch.from_numpy(np.array(image_refs).astype(np.uint8)).to(self.device)\n",
    "#         stat_str += '  self.image_refs: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        \n",
    "        # set clean_plates:\n",
    "        clean_plates = kwargs.get('clean_plates', None)\n",
    "        self.clean_plates = torch.from_numpy(np.array(clean_plates).astype(np.float32)).to(self.device)\n",
    "#         stat_str += '  self.clean_plates: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        \n",
    "        # load texturemaps: [0.0, 1.0] float\n",
    "        texturemap_shape = kwargs.get('texturemap_shape', None)\n",
    "#         texture_map_torch = torch.from_numpy(np.ones((1, texturemap_shape[0], texturemap_shape[1], texturemap_shape[2])).astype(np.float32)).to(self.device)\n",
    "        texture_map_torch = torch.from_numpy(np.random.rand(1, texturemap_shape[0], texturemap_shape[1], texturemap_shape[2]).astype(np.float32)).to(self.device)\n",
    "        self.texture_map = nn.Parameter(texture_map_torch, requires_grad=True)\n",
    "#         stat_str += '  self.texture_map: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        \n",
    "        # batch_size\n",
    "        self.batch_size = kwargs.get('batch_size', None)\n",
    "        self.num_renders = len(self.image_refs)\n",
    "        self.n_batch = int(self.num_renders / self.batch_size)\n",
    "        \n",
    "        # set mesh\n",
    "        mesh_path = kwargs.get('mesh_path', None)\n",
    "        self.mesh = self._load_mesh(self.device, [mesh_path], texture_map_torch)\n",
    "        self.meshes = None\n",
    "#         stat_str += '  self.meshes: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        \n",
    "        # vertex deformations\n",
    "        self.vert_normals = self.mesh.verts_normals_packed()\n",
    "        deform_verts = torch.from_numpy(np.zeros((self.vert_normals.shape[0], 1), dtype=np.float32)).to(self.device)\n",
    "        self.deform_verts = nn.Parameter(deform_verts, requires_grad=True)\n",
    "        \n",
    "        # init renderers\n",
    "        cam_pararms = kwargs.get('cam_params', None)\n",
    "        self.batch_renderers = self._init_renderer(cam_params=cam_pararms, batch_size=self.batch_size, n_batch=self.n_batch)\n",
    "#         stat_str += '  self.renderers: {}\\n'.format(self.get_gpu_stats(True))\n",
    "        \n",
    "        self.stat_gpu = stat_str\n",
    "        \n",
    "    def forward(self):\n",
    "        loss = 0\n",
    "        losses_dict = {'pixel': 0.0, 'mesh_normal': 0.0, 'mesh_laplacian': 0.0}\n",
    "        stat_str = ''\n",
    "        log = ''\n",
    "        t0 = time.time()\n",
    "#         normal_deforms = self.deform_verts * self.vert_normals\n",
    "#         deformed_mesh = self.mesh.offset_verts(normal_deforms)\n",
    "#         self.meshes = deformed_mesh.extend(self.batch_size)\n",
    "        self.meshes = self.mesh.extend(self.batch_size)\n",
    "        \n",
    "        images_out = torch.zeros(self.image_refs.shape[0], self.image_refs.shape[1], self.image_refs.shape[2])\n",
    "        t1 = time.time()\n",
    "        log += 'forward\\n'\n",
    "        log += ' - {:<10}: {:.3f}s\\n'.format('data prep', t1 - t0)\n",
    "        for batch_idx in range(self.n_batch):\n",
    "            t2 = time.time()\n",
    "            i0 = batch_idx*batch_size\n",
    "            i1 = i0 + batch_size\n",
    "            \n",
    "            # [0.0, 1.0] float32 in gpu -> change to [0.0, 255.0] cpu. shape (batch_size, W, H, 4)\n",
    "            images0, log_render = self.batch_renderers[batch_idx](meshes_world=self.meshes, texture_maps=self.texture_map)\n",
    "            \n",
    "            # shape (batch_size, W, H)\n",
    "            bgs = self.clean_plates[i0:i1].squeeze()\n",
    "            \n",
    "            # merge fg, bg\n",
    "            image_cur = self._merge_fg_bg(images0, bgs)\n",
    "            \n",
    "            # save for output\n",
    "            images_out[i0:i1] = image_cur\n",
    "            \n",
    "            # [0, 255] float32 in cpu\n",
    "            image_refs = self.image_refs[i0:i1]\n",
    "\n",
    "            loss_i = (torch.mean((image_cur - image_refs) ** 2) / 255.0)\n",
    "            loss = loss + loss_i\n",
    "#             stat_str += '  [{:02}] batch loss computed   : {}\\n'.format(batch_idx, self.get_gpu_stats(True))\n",
    "            \n",
    "            losses_dict['pixel'] += loss_i\n",
    "            t3 = time.time()\n",
    "            log += ' - [{}/{}] {:<10}: {:.3f}s\\n'.format(batch_idx+1, self.n_batch, 'batch render', t3 - t2)\n",
    "            log += '   ------------------------------------\\n'\n",
    "            log += log_render\n",
    "            log += '   ------------------------------------\\n'\n",
    "#         loss_normal = mesh_normal_consistency(deformed_mesh)\n",
    "#         loss_laplacian = mesh_laplacian_smoothing(deformed_mesh, method='uniform')\n",
    "        loss_normal = 0.0\n",
    "        loss_laplacian = 0.0\n",
    "        \n",
    "        losses_dict['mesh_normal'] += loss_normal\n",
    "        losses_dict['mesh_laplacian'] += loss_laplacian\n",
    "            \n",
    "        loss = 1.0*loss + 0.5*loss_normal + 0.5*loss_laplacian\n",
    "        return loss, images_out, self.texture_map, stat_str, losses_dict, log\n",
    "    \n",
    "    def _merge_fg_bg(self, fg, bg):\n",
    "        \"\"\"\n",
    "        fg: mesh rendering. [N, W, H, 4]: [0, 1.0] float\n",
    "        bg: clean plate. [N, W, H]: [0, 255] uint8\n",
    "        \"\"\"\n",
    "        out = torch.where(fg[...,0] < 1.0, 255.0*fg[...,0], bg)\n",
    "        if len(out.shape) < 3:\n",
    "            out = out.unsqueeze(0)\n",
    "        return out\n",
    "\n",
    "    def get_gpu_stats(self, output_str=True):\n",
    "        mb_reserved = torch.cuda.memory_reserved() * 0.000001\n",
    "        mb_alloc = torch.cuda.memory_allocated() * 0.000001\n",
    "        mb_cached = torch.cuda.memory_cached() * 0.000001\n",
    "        if output_str:\n",
    "            return 'alloc={:,.0f}MB | cached={:,.0f}MB | reserved={:,.0f}MB'.format(mb_alloc, mb_cached, mb_reserved)\n",
    "        else:\n",
    "            return mb_alloc, mb_cached, mb_reserved\n",
    "        \n",
    "    def _load_mesh(self, device, mesh_paths, texturemap_torch):\n",
    "        # load mesh\n",
    "        meshes = load_objs_as_meshes(mesh_paths, universal_texturemap=texturemap_torch, device=device)\n",
    "        return meshes\n",
    "    \n",
    "    def save_parameters(self, out_path):\n",
    "        deform_verts = self.deform_verts.detach().cpu().numpy()\n",
    "        np.save(out_path, deform_verts)\n",
    "        print('Parameters saved:', out_path)\n",
    "        \n",
    "    def load_parameters(self, in_path):\n",
    "        self.deform_verts = nn.Parameter(torch.from_numpy(np.load(in_path)).to(self.device))\n",
    "        print('Parameters loaded: {}'.format(self.deform_verts.shape))\n",
    "        \n",
    "    def export_obj(self, out_path):\n",
    "        normal_deforms = self.deform_verts * self.vert_normals\n",
    "        deformed_mesh = self.mesh.offset_verts(normal_deforms)\n",
    "\n",
    "        verts = deformed_mesh.verts_packed()\n",
    "        faces = deformed_mesh.faces_packed()\n",
    "        vnormals = deformed_mesh.verts_normals_list()[0]\n",
    "        fnormals = deformed_mesh.faces_normals_list()[0]\n",
    "\n",
    "        assert(faces.shape[0] == fnormals.shape[0])\n",
    "        assert(vnormals.shape[0] == verts.shape[0])\n",
    "\n",
    "        with open(out_path, 'w+') as f:\n",
    "            f.write('# OBJ file created by Hyojoon Park.\\n')\n",
    "            f.write('###########################\\n')\n",
    "            f.write('# Vertices:       {}\\n'.format(verts.shape[0]))\n",
    "            f.write('# Vertex normals: {}\\n'.format(vnormals.shape[0]))\n",
    "            f.write('# Faces:          {}\\n'.format(faces.shape[0]))\n",
    "            f.write('###########################\\n')\n",
    "\n",
    "            for i in range(verts.shape[0]):\n",
    "                f.write('vn {:.4f} {:.4f} {:.4f}\\n'.format(vnormals[i][0], vnormals[i][1], vnormals[i][2]))\n",
    "                f.write('v {:.4f} {:.4f} {:.4f}\\n'.format(verts[i][0], verts[i][1], verts[i][2]))\n",
    "\n",
    "            for i in range(faces.shape[0]):\n",
    "                f.write(\"f\")\n",
    "                face = faces[i, :]\n",
    "                for fi in range(face.shape[0]):\n",
    "                    f.write(' {0:.0f}//{0:.0f}'.format(face[fi] + 1, fnormals[fi] + 1))\n",
    "#                     f.write(' {0:.0f}'.format(face[fi]))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        print('Obj exported to:', out_path)\n",
    "        \n",
    "    def _init_renderer(self, cam_params, batch_size, n_batch):\n",
    "        batch_renderers = []\n",
    "        \n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=self.image_size, \n",
    "            blur_radius=0.0, \n",
    "            faces_per_pixel=1, \n",
    "            bin_size = 0, # this setting controls whether naive or coarse-to-fine rasterization is used\n",
    "            max_faces_per_bin = None  # this setting is for coarse rasterization\n",
    "        )\n",
    "        \n",
    "        print('  - batch size: {}, num_batches: {}'.format(batch_size, n_batch))\n",
    "        print('  - cameras   : {}'.format(cam_params['T'].shape[0]))\n",
    "        locations = torch.from_numpy(np.array([0, 0, 3000])).to(self.device)\n",
    "        a_diffuse = 0\n",
    "        a_ambient = 0.5\n",
    "        s = torch.from_numpy(np.zeros((1, 3)).astype(np.float32)).to(self.device)\n",
    "        d = torch.from_numpy(np.ones((1, 3)).astype(np.float32)*a_diffuse).to(self.device)\n",
    "        a = torch.from_numpy(np.ones((1, 3)).astype(np.float32)*a_ambient).to(self.device)\n",
    "        light = PointLights(device=self.device, location=[[1000, 1000, 1000]], specular_color=s, ambient_color=a, diffuse_color=d)\n",
    "        light.location = locations\n",
    "        light.specular_color = s\n",
    "        light.diffuse_color = d\n",
    "        light.ambient_color = a\n",
    "        \n",
    "        for batch_idx in range(n_batch):\n",
    "            i0 = batch_idx*batch_size\n",
    "            i1 = i0 + batch_size\n",
    "            R = cam_params['R'][i0:i1]\n",
    "            T = cam_params['T'][i0:i1]\n",
    "            focal_length = cam_params['fl'][i0:i1]\n",
    "            principal_point = cam_params['pp'][i0:i1]\n",
    "            cameras = SfMPerspectiveCameras(device=self.device, R=R, T=T, principal_point=principal_point, focal_length=focal_length)\n",
    "\n",
    "            renderer = MeshRenderer(\n",
    "                    rasterizer=MeshRasterizer(\n",
    "                        cameras=cameras,\n",
    "                        raster_settings=raster_settings\n",
    "                    ),\n",
    "                    shader=TexturedSoftPhongShader(\n",
    "                        device=self.device, \n",
    "                        cameras=cameras,\n",
    "                        lights=light\n",
    "                    )\n",
    "                )\n",
    "            batch_renderers.append(renderer)\n",
    "        print('  - renderers   : {}'.format(len(batch_renderers)))\n",
    "        return batch_renderers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mesh, camera, images, and feed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cameras(cam_path, device, actual_img_shape):\n",
    "    h = actual_img_shape[0]\n",
    "    w = actual_img_shape[1]\n",
    "    img_size = min(w, h)\n",
    "    \n",
    "    # load cameras\n",
    "    cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "\n",
    "    with open(cam_path, 'r') as f:\n",
    "        j = json.load(f)\n",
    "        camera_params = j['cam_params']\n",
    "\n",
    "    cameras = []\n",
    "    cam_params = []\n",
    "    cam_pos = []\n",
    "    Rs, Ts, focal_lengths, principal_points = [], [], [], []\n",
    "    for cam_idx, cam in enumerate(cams):\n",
    "        cam_param = camera_params[str(cam_idx)]\n",
    "        # for undistortion\n",
    "        fx = cam_param['fx']\n",
    "        fy = cam_param['fy']\n",
    "        cx = cam_param['cx']\n",
    "        cy = cam_param['cy']\n",
    "        k1 = cam_param['k1']\n",
    "        k2 = cam_param['k2']\n",
    "        k3 = cam_param['k3']\n",
    "        p1 = cam_param['p1']\n",
    "        p2 = cam_param['p2']\n",
    "        \n",
    "        rvec = np.float32(cam_param['rvec'])\n",
    "        T = np.float32(cam_param['tvec'])\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        Rs.append(R.T)\n",
    "        Ts.append(T)\n",
    "        \n",
    "        if cam_idx % 6 == 0:\n",
    "            cam_pos.append(-R.T.dot(T))\n",
    "        \n",
    "        cx_corrected = cx*2/img_size - w/img_size\n",
    "        cy_corrected = cy*2/img_size - h/img_size\n",
    "        fx_corrected = fx*2/img_size\n",
    "        fy_corrected = fy*2/img_size\n",
    "        principal_point = np.array([cx_corrected, cy_corrected]).astype(np.float32)\n",
    "        focal_length = np.array([fx_corrected, fy_corrected]).astype(np.float32)\n",
    "        focal_lengths.append(focal_length)\n",
    "        principal_points.append(principal_point)\n",
    "\n",
    "        K = np.float32([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "        dist = np.float32([k1, k2, p1, p2, k3])\n",
    "        cam_params.append({'K': K, 'dist': dist, 'R': R, 'T': T, 'fx': fx, 'fy': fy, 'cx': cx, 'cy': cy})\n",
    "    \n",
    "    R_torch = torch.from_numpy(np.array(Rs).astype(np.float32))\n",
    "    T_torch = torch.from_numpy(np.array(Ts).astype(np.float32))\n",
    "    focal_length = torch.from_numpy(np.array(focal_lengths).astype(np.float32))\n",
    "    principal_point = torch.from_numpy(np.array(principal_points).astype(np.float32))\n",
    "    out_for_torch = {'R': R_torch, 'T': T_torch, 'fl': focal_length, 'pp': principal_point}\n",
    "    return cameras, cam_params, out_for_torch\n",
    "\n",
    "def load_images(img_dir, cam_params):\n",
    "    img_paths = sorted(glob.glob(img_dir + '/*.jpg'))\n",
    "    image_refs0 = []\n",
    "    image_refs_undistort = []\n",
    "    for i, path in enumerate(img_paths):\n",
    "        # img = imageio.imread(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_undist = _undistort(img, cam_params[i])\n",
    "        image_refs0.append(img)\n",
    "        image_refs_undistort.append(img_undist)\n",
    "\n",
    "    w = 2160 / 2\n",
    "    image_refs_cropped = []\n",
    "    for i in range(len(image_refs_undistort)):\n",
    "        image = image_refs_undistort[i]\n",
    "        cx = image.shape[1] / 2\n",
    "\n",
    "        image = image_refs_undistort[i].astype(np.uint8)\n",
    "        img = image[:, int(cx-w):int(cx+w)]\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = cv2.flip(img, -1)\n",
    "        image_refs_cropped.append(img)\n",
    "    return image_refs0, image_refs_undistort, image_refs_cropped\n",
    "                         \n",
    "def _undistort(img, cam_param):\n",
    "    # undistort a single image)\n",
    "    h, w = img.shape[:2]\n",
    "    # cv2.undistort(src, cameraMatrix, distCoeffs[, dst[, newCameraMatrix]]) â†’ dst\n",
    "    img = cv2.undistort(img, cam_param['K'], cam_param['dist'], None, None)\n",
    "    return img\n",
    "                         \n",
    "def load_clean_plates(img_dir, cam_params):\n",
    "    img_paths = sorted(glob.glob(img_dir + '/*.pgm'))\n",
    "    images0 = []\n",
    "    images_undistort = []\n",
    "    for i, path in enumerate(img_paths):\n",
    "        # img = imageio.imread(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_undist = _undistort(img, cam_params[i])\n",
    "        images0.append(img)\n",
    "        images_undistort.append(img_undist)\n",
    "\n",
    "    w = 2160 / 2\n",
    "    clean_plates_cropped = []\n",
    "    for i in range(len(images_undistort)):\n",
    "        image = images_undistort[i]\n",
    "        cx = image.shape[1] / 2\n",
    "\n",
    "        image = images_undistort[i].astype(np.uint8)\n",
    "        img = image[:, int(cx-w):int(cx+w)]\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = cv2.flip(img, -1)\n",
    "        # img = np.dstack([img, img, img])\n",
    "        clean_plates_cropped.append(img)\n",
    "    return images0, images_undistort, clean_plates_cropped "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "cam_path = r'D:\\CalibrationData\\CameraCalibration\\2020_03_22_NewSuitDesignCapture\\FinalCamParams\\cam_params.json'\n",
    "mesh_path = r'D:\\1_Projects\\200325_PyTorch3d_Toy\\4_data\\input\\2020_03_28_SMPL_UV\\SMPL_registration\\SMPLFit_TPose.obj'\n",
    "img_dir = './4_data/input/2020_03_28_SMPL_UV/SMPL_registration/TPose'\n",
    "clean_plate_dir = r'D:\\200330_ToJanKeller\\data\\input\\clean_plate'\n",
    "\n",
    "# number of batch will be automatically computed\n",
    "batch_size = 1\n",
    "\n",
    "texturemap_shape = (16, 16, 1)\n",
    "image_size = 16\n",
    "\n",
    "# input image size\n",
    "actual_img_shape = (2160, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam_path = './4_data/input/CameraCalibration/2020_03_22_NewSuitDesignCapture\\FinalCamParams\\cam_params.json'\n",
    "# mesh_path = './4_data/input/2020_03_28_SMPL_UV/SMPL_registration/SMPLFit_TPose.obj'\n",
    "# img_dir = './4_data/input/2020_03_28_SMPL_UV/SMPL_registration/TPose'\n",
    "# texturemap_shape = (2160, 2160, 1)\n",
    "# image_size = 2160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 4000)\n",
      "(16, 16)\n"
     ]
    }
   ],
   "source": [
    "device = device_gpu\n",
    "cameras, cam_params, cams_torch = load_cameras(cam_path, device, actual_img_shape=actual_img_shape)\n",
    "img_refs_original, img_refs_undistorted, img_refs = load_images(img_dir, cam_params)\n",
    "print(img_refs_undistorted[0].shape)\n",
    "clean_plates_original, clean_plates_undistort, clean_plates = load_clean_plates(clean_plate_dir ,cam_params)\n",
    "print(clean_plates[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_refs_original[0]\n",
    "print('Image original =========')\n",
    "print(img.shape, ',', np.max(img), ',', img.dtype)\n",
    "print('{:,.2f} Mb'.format(img.nbytes * 0.000001))\n",
    "\n",
    "print()\n",
    "img = img_refs[0]\n",
    "print('Image cropped =========')\n",
    "print(img.shape, ',', np.max(img), ',', img.dtype)\n",
    "print('{:,.2f} Mb'.format(img.size * img.itemsize * 0.000001))\n",
    "print()\n",
    "img = clean_plates[0]\n",
    "print('Clean plate cropped =========')\n",
    "print(img.shape, ',', np.max(img), ',', img.dtype)\n",
    "print('{:,.2f} Mb'.format(img.size * img.itemsize * 0.000001))\n",
    "\n",
    "i = 5\n",
    "fig, ax = plt.subplots(1, 3, figsize=(21, 7))\n",
    "ax[0].imshow(img_refs_original[i], cmap='gray')\n",
    "ax[0].set_title('original')\n",
    "ax[1].imshow(img_refs_undistorted[i], cmap='gray')\n",
    "ax[1].set_title('undistorted')\n",
    "ax[2].imshow(img_refs[i], cmap='gray')\n",
    "ax[2].set_title('undistorted & cropped')\n",
    "ax[2].invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(21, 7))\n",
    "ax[0].imshow(clean_plates_original[i], cmap='gray')\n",
    "ax[0].set_title('original-clean')\n",
    "ax[1].imshow(clean_plates_undistort[i], cmap='gray')\n",
    "ax[1].set_title('undistorted-clean')\n",
    "ax[2].imshow(clean_plates[i], cmap='gray')\n",
    "ax[2].set_title('undistorted & cropped-clean')\n",
    "ax[2].invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(device_gpu, img_dir=img_dir, cam_params=cams_torch, image_refs=img_refs, clean_plates=clean_plates, texturemap_shape=texturemap_shape, mesh_path=mesh_path, image_size=image_size, batch_size=batch_size)\n",
    "texture_maps = model.texture_map\n",
    "print('texture_map: {:,.2f}=={:,.2f} Mb'.format(texture_maps.element_size() * texture_maps.nelement() * 0.000001, texture_maps.detach().cpu().numpy().nbytes*0.000001))\n",
    "texture_maps_np = texture_maps.detach().cpu().numpy()\n",
    "print('  {} {:,.2f}Mb {} {}'.format(texture_maps.shape, texture_maps_np.nbytes*0.000001, texture_maps.dtype, np.max(texture_maps_np)))\n",
    "img = model.image_refs[0]\n",
    "print('ref image: {}, {:,.2f} Mb'.format(img.shape, img.element_size() * img.nelement() * 0.000001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch3d mesh rendering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import image_grid\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "t0 = time.time()\n",
    "loss, images_rendered, texture_map, stats_gpu, loss_dict, log = model()\n",
    "t1 = time.time()\n",
    "# model.save_parameters('./7_data/output/deform_verts.npy')\n",
    "# model.export_obj('./7_data/output/obj.obj')\n",
    "t2 = time.time()\n",
    "print('forward:{:.2f}s, save:{:.2f}'.format(t1-t0, t2-t1))\n",
    "\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "print(log)\n",
    "# mesh from pytorch3d\n",
    "i = 0\n",
    "img_mesh = images_rendered.squeeze().detach().cpu().numpy()\n",
    "print(img_mesh.shape)\n",
    "for batch_idx in range(model.n_batch):\n",
    "    fig, ax = plt.subplots(1, model.batch_size, figsize=(model.batch_size*5, 5))\n",
    "    if model.batch_size > 1:\n",
    "        ax = ax.ravel()\n",
    "        for n in range(model.batch_size):\n",
    "            img_mesh2 = img_mesh[i]\n",
    "            img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "            ax[n].set_title('batch[{}][{}] | i={}'.format(batch_idx, i, batch_idx*batch_size + i + 1))\n",
    "            ax[n].imshow(img_mesh2, cmap='gray')\n",
    "            i += 1\n",
    "    else:\n",
    "        img_mesh2 = img_mesh[i]\n",
    "        img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "        ax.set_title('batch[{}][{}] | i={}'.format(batch_idx, i, batch_idx*batch_size + i + 1))\n",
    "        ax.imshow(img_mesh2, cmap='gray')\n",
    "        i += 1\n",
    "    break\n",
    "plt.show()\n",
    "# print(stats_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add clean plate background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_fg_bg(fg, bg):\n",
    "    \"\"\"\n",
    "    fg: mesh rendering. [W, H, 4]: [0, 1.0] float\n",
    "    bg: clean plate. [W, H]: [0, 255] uint8\n",
    "    \"\"\"\n",
    "    max_pixel = np.max(fg)\n",
    "    out = np.where(fg[...,0] < max_pixel, 255*fg[...,0], bg)\n",
    "    return out\n",
    "    \n",
    "img_idx = 0\n",
    "cp = clean_plates[img_idx]\n",
    "img = img_mesh[img_idx]\n",
    "img2 = merge_fg_bg(img, cp)\n",
    "plt.imshow(img2, cmap='gray', vmin=0, vmax=255)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reprojections of obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_vertices = model.meshes.verts_packed().cpu()\n",
    "mesh_points = []\n",
    "\n",
    "t0 = time.time()\n",
    "for cam_idx in range(16):\n",
    "    params = cam_params[cam_idx]\n",
    "    pts = reproject(params, mesh_vertices, distort=False)\n",
    "    mesh_points.append(pts)\n",
    "t1 = time.time()\n",
    "print('{:.2f}s'.format(t1-t0))\n",
    "print(pts.shape)\n",
    "print(len(mesh_points))\n",
    "del mesh_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in range(16):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # bg\n",
    "    img_bg = img_refs[i]\n",
    "    img_bg = cv2.flip(img_bg, -1)\n",
    "    plt.imshow(img_bg, cmap='gray')\n",
    "    \n",
    "    # mesh from pytorch3d\n",
    "    img_mesh = images_rendered[i].squeeze().detach().cpu().numpy()[..., :3]\n",
    "    img_mesh2 = img_mesh\n",
    "    img_mesh2 = cv2.flip(img_mesh2, -1)\n",
    "    plt.imshow(img_mesh2, alpha=0.5, cmap='gray')\n",
    "    \n",
    "    pts = mesh_points[i]\n",
    "    pts_small_x = (pts[:, 0] - (4000-2160)*0.5) * image_size/2160\n",
    "    pts_small_y = pts[:, 1] * image_size/2160\n",
    "    pts_small = np.stack([pts_small_x, pts_small_y]).T\n",
    "    pts_center = np.mean(pts_small, axis=0)\n",
    "    plt.scatter(pts_small[:, 0], pts_small[:, 1], c='b', s=0.01)\n",
    "    plt.title('Camera {}'.format(i))\n",
    "    \n",
    "    # plot centers\n",
    "    plt.scatter(pts_center[0], pts_center[1], c='r')\n",
    "    \n",
    "    if i == 0:\n",
    "        print('reference image:', np.max(img_bg), img_bg.dtype, img_bg.shape)\n",
    "        print('rendered pytorch image :', np.max(img_mesh), img_mesh.dtype, img_mesh.shape, ', {:,.2f} Mb'.format(img_mesh.nbytes * 0.000001), np.max(img_mesh))\n",
    "        print('rendered pytorch image2:', np.max(img_mesh2), img_mesh2.dtype, img_mesh2.shape, ', {:,.2f} Mb'.format(img_mesh2.nbytes * 0.000001), np.max(img_mesh2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_LR(e, lr, losses, images, imgR, out_path):\n",
    "    cams = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "    img_meshes = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i].detach().squeeze(0).cpu().numpy()\n",
    "        img_mesh = np.clip(cv2.flip(img, -1), a_min=0.0, a_max=1.0)\n",
    "        img_meshes.append(img_mesh)\n",
    "        \n",
    "    fig = plt.figure(figsize=(18, 3), tight_layout=True)\n",
    "    \n",
    "    gs = fig.add_gridspec(2, 12)\n",
    "    for r in range(2):\n",
    "        for c in range(8):\n",
    "            i = r*8 + c\n",
    "            ax = fig.add_subplot(gs[r, c])\n",
    "            ax.set_title('{}'.format(cams[i]))\n",
    "            ax.imshow(img_meshes[i], cmap='gray')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    ax = fig.add_subplot(gs[:, 8:10])\n",
    "    ax.plot(losses)\n",
    "    ax.set_title('loss={:.8f}'.format(losses[-1]))\n",
    "    \n",
    "    ax = fig.add_subplot(gs[:, 10:12])\n",
    "    imgR2 = imgR.squeeze().detach().cpu().numpy()\n",
    "    imgR2 = np.clip(imgR2, a_min=0.0, a_max=1.0)\n",
    "    ax.imshow(imgR2, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax.set_title('Learned Texturemap')\n",
    "    \n",
    "    plt.suptitle('Epoch: {:<10}  lr: {:<.4f}'.format(e, lr))\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close('all')\n",
    "    \n",
    "    saved_img = imageio.imread(save_path)\n",
    "    return saved_img\n",
    "\n",
    "def visualize2(e, lr, losses, losses_dict, image1, image2, image3, out_path):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(24, 6), tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    ax[0].plot(losses)\n",
    "    ax[0].set_title('Epoch={}, lr={:.4f}, loss={:.4f}, pixel_loss={:.4f}'.format(e, lr, losses[-1], losses_dict['pixel']))\n",
    "    \n",
    "    ax[1].imshow(image1, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].set_title('Current image')\n",
    "    \n",
    "    ax[2].imshow(image2, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].set_title('Target image')\n",
    "\n",
    "    ax[3].imshow(image3, cmap='gray', vmin=0, vmax=1.0)\n",
    "    ax[3].set_title('Learned texturemap')\n",
    "\n",
    "    \n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close('all')\n",
    "    \n",
    "    saved_img = imageio.imread(save_path)\n",
    "    return saved_img\n",
    "    \n",
    "def get_gpu_stats(output_str=True):\n",
    "    mb_reserved = torch.cuda.memory_reserved() * 0.000001\n",
    "    mb_alloc = torch.cuda.memory_allocated() * 0.000001\n",
    "    mb_cached = torch.cuda.memory_cached() * 0.000001\n",
    "    if output_str:\n",
    "        return 'alloc={:,.0f}MB | cached={:,.0f}MB | reserved={:,.0f}MB'.format(mb_alloc, mb_cached, mb_reserved)\n",
    "    else:\n",
    "        return mb_alloc, mb_cached, mb_reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'./7_data/output/plot.png'\n",
    "# saved_img = visualize_LR(0, 0, [100, 10, 1], images_rendered, texture_map, save_path)\n",
    "i = 0\n",
    "image1 = images_rendered.squeeze().detach().cpu().numpy()[i]\n",
    "image2 = img_refs[i]\n",
    "image3 = texture_map.detach().squeeze().cpu().numpy()\n",
    "saved_img = visualize2(1, 2, [3, 4, 5], image1, image2, image3, save_path)\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.imshow(saved_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init mesh & texturemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- torch.cuda.empty_cache() -----\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n",
      "  - batch size: 1, num_batches: 16\n",
      "  - cameras   : 16\n",
      "  - renderers   : 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "print('----- torch.cuda.empty_cache() -----')\n",
    "torch.cuda.empty_cache()\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "model = Model(device_gpu, img_dir=img_dir, cam_params=cams_torch, image_refs=img_refs, clean_plates=clean_plates, texturemap_shape=texturemap_shape, mesh_path=mesh_path, image_size=image_size, batch_size=batch_size)\n",
    "\n",
    "stat_gpu = model.stat_gpu\n",
    "print(stat_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, images, texels, stat_gpu, losses_dict, _ = model()\n",
    "i = 0\n",
    "save_path = r'./7_data/output/plot.png'\n",
    "image1 = images.squeeze().detach().cpu().numpy()[i]\n",
    "image2 = img_refs[i]\n",
    "image3 = texels.detach().squeeze().cpu().numpy()\n",
    "saved_img = visualize2(1, 2, [3, 4, 5], losses_dict, image1, image2, image3, save_path)\n",
    "plt.figure(figsize=(40, 10))\n",
    "plt.imshow(saved_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log output: ./7_data/output/log_20200415_00h55m.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-59020ac77a3c>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  loop = tqdm_notebook(range(1000000000))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd91e1a88bce4106851976acedb29272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "function _RasterizeFaceVertsBackward returned an incorrect number of gradients (expected 10, got 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-59020ac77a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mstat_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstat_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mstat_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'4 {:<21}: {}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'backward'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_gpu_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch3d\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch3d\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: function _RasterizeFaceVertsBackward returned an incorrect number of gradients (expected 10, got 9)"
     ]
    }
   ],
   "source": [
    "out_dir = './7_data/output'\n",
    "save_path = out_dir + '/plot.png'\n",
    "\n",
    "# filename_output = './4_data/output/4b/out.gif'\n",
    "# writer = imageio.get_writer(filename_output, mode='I', duration=0.3)\n",
    "now = datetime.now()\n",
    "hour = str(now.hour)\n",
    "minute = str(now.minute)\n",
    "date_str = '{}{:>02}{:>02}_{:>02}h{:>02}m'.format(now.year, now.month, now.day, hour, minute)\n",
    "log_path = out_dir + '/log_{}.txt'.format(date_str)\n",
    "__output_log(log_path, '========== {} Start ==========================\\n'.format(date_str))\n",
    "print('Log output: {}'.format(log_path))\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loop = tqdm_notebook(range(1000000000))\n",
    "\n",
    "losses = []\n",
    "loss_belows, loss_aboves = 0, 0\n",
    "losses_below, losses_above = [], []\n",
    "latest_states = {}\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    for e in loop:\n",
    "        stat_str = '1 {:<21}: {}\\n'.format('epoch starts'.format(e), get_gpu_stats())\n",
    "        output_texels = (e % 10 == 0)\n",
    "        \n",
    "        if e > 0 and e % 200 == 0:\n",
    "            optimizer.param_groups[0]['lr'] *= 0.5\n",
    "            \n",
    "        t0 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        stat_str += '2 {:<21}: {}\\n'.format('optimizer.zero_grad()', get_gpu_stats())\n",
    "        t1 = time.time()\n",
    "        \n",
    "        if output_texels:\n",
    "            loss, images, texels, stat_gpu, loss_dict, _ = model()\n",
    "            latest_states['loss'] = loss\n",
    "            latest_states['images'] = images.clone()\n",
    "            latest_states['texels'] = texels.clone()\n",
    "            latest_states['loss_dict'] = loss_dict\n",
    "        else:\n",
    "            loss, _, _, stat_gpu, loss_dict, _ = model()\n",
    "            latest_states['loss'] = loss\n",
    "            latest_states['loss_dict'] = loss_dict\n",
    "            \n",
    "        if e > 0 and e % 50 == 0:\n",
    "            model.save_parameters('./7_data/output/deform_verts.npy')\n",
    "            model.export_obj('./7_data/output/obj.obj')\n",
    "            \n",
    "        stat_str += '3 {:<21}: {}\\n'.format('forward', get_gpu_stats())\n",
    "        stat_str += stat_gpu\n",
    "        t2 = time.time()\n",
    "        loss.backward()\n",
    "        stat_str += '4 {:<21}: {}\\n'.format('backward', get_gpu_stats())\n",
    "        t3 = time.time()\n",
    "        \n",
    "        optimizer.step()\n",
    "        stat_str += '5 {:<21}: {}\\n'.format('optimizer.step()', get_gpu_stats())\n",
    "        t4 = time.time()\n",
    "        losses.append(loss)\n",
    "        losses_below.append(loss_belows)\n",
    "        losses_above.append(loss_aboves)\n",
    "\n",
    "        loop.set_description('[{}/{}] loss={:.6f}'.format(e, len(loop), loss.data))\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if output_texels:\n",
    "            # Save outputs to create a GIF. \n",
    "            t10 = time.time()\n",
    "            \n",
    "            save_idx = 0\n",
    "            image1 = images.squeeze().detach().cpu().numpy()[save_idx]\n",
    "            image2 = img_refs[save_idx]\n",
    "            image3 = texels.detach().squeeze().cpu().numpy()\n",
    "            saved_img = visualize2(e, lr, losses, loss_dict, image1, image2, image3, save_path)\n",
    "            # image_out = visualize_LR(e, lr, losses, images, texels, save_path)\n",
    "            plt.figure()\n",
    "            plt.imshow(saved_img)\n",
    "            plt.title(\"iter: %d, lr: %0.4f, loss: %0.8f\" % (e, lr, loss.data))\n",
    "            plt.grid(\"off\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            plt.close('all')\n",
    "            \n",
    "            texels_np = model.texture_map.detach().cpu().numpy()\n",
    "            np.save(out_dir + '/texturemap.npy', texels_np)\n",
    "            del texels_np\n",
    "            \n",
    "            texturemap_out = (255.0*np.clip(model.texture_map.detach().squeeze().cpu().numpy(), a_min=0, a_max=1.0)).astype(np.uint8)\n",
    "            im = Image.fromarray(texturemap_out)\n",
    "            im.save(out_dir + '/texturemap_learned.png', dpi=(600, 600))\n",
    "            t11 = time.time()\n",
    "\n",
    "#             image_out = image_out / 255.0\n",
    "#             image_out = np.clip(image_out, 0, 1)\n",
    "#             image_out = img_as_ubyte(image_out)\n",
    "#             writer.append_data(image_out)\n",
    "            t12 = time.time()\n",
    "            \n",
    "            __output_log(log_path, '{:03} | plot({:.2f}s) | gif({:.2f}s)\\n'.format(e+1, t11-t10, t12-t11))\n",
    "#             stat_str += '  {:<21}: {}\\n'.format('plotting', get_gpu_stats())\n",
    "        # execution time\n",
    "        t01 = t1-t0\n",
    "        t12 = t2-t1\n",
    "        t23 = t3-t2\n",
    "        t34 = t4-t3\n",
    "        t5 = time.time()\n",
    "        \n",
    "        mb_alloc = torch.cuda.memory_allocated() * 0.000001\n",
    "        mb_cached = torch.cuda.memory_cached() * 0.000001\n",
    "        now = datetime.now()\n",
    "        hour = str(now.hour)\n",
    "        minute = str(now.minute)\n",
    "        second = str(now.second)\n",
    "        now_str = '{:>02}:{:>02}:{:>02}'.format(hour, minute, second)\n",
    "        __output_log(log_path, '{} | {:03} | {:.2f}s | lr={:.8f} | loss={:.6f} | pixel_l={:.4f} | normal_l={:.4f} | lap_l={:.4f} | zero_grad({:.2f}s) | forward({:.2f}s) | backward({:.2f}s) | step({:.2f}s) | GPU_allocated({:,.2f}Mb) | GPU_cached({:,.2f}Mb)\\n'.format(now_str, e+1, t5-t0, lr, loss, loss_dict['pixel'], loss_dict['mesh_normal'], loss_dict['mesh_laplacian'], t01, t12, t23, t34, mb_alloc, mb_cached))\n",
    "        \n",
    "        # clean up\n",
    "        if output_texels:\n",
    "            del loss, images, texels\n",
    "        else:\n",
    "            del loss\n",
    "        stat_str += '7 {:<21}: {}\\n'.format('clean up', get_gpu_stats())\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        stat_str += '8 {:<21}: {}\\n'.format('empty_cache()', get_gpu_stats())\n",
    "        __output_log(log_path, '{}'.format(stat_str))\n",
    "        if e > 620:\n",
    "            break\n",
    "            \n",
    "torch.cuda.empty_cache()\n",
    "# loss, images, texels, stat_str = model()\n",
    "loss, images, texels = latest_states['loss'], latest_states['images'], latest_states['texels']\n",
    "print(stat_str)\n",
    "\n",
    "save_dir = out_dir\n",
    "for i in range(len(images)):\n",
    "    print(' ', i+1, end='')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12), tight_layout=True)\n",
    "    img = images[i].detach().cpu().numpy()\n",
    "    ax[0].imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[1].imshow(img_refs[i], cmap='gray')\n",
    "    ax[1].invert_yaxis()\n",
    "    plt.savefig(save_dir + '/compare_cam{}.png'.format(i+1), dpi=300)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# # plt.plot(losses, 'k')\n",
    "# plt.plot(losses_above, 'r')\n",
    "# plt.plot(losses_below, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# loss, images, texels, stat_str = model()\n",
    "loss, images, texels = latest_states['loss'], latest_states['images'], latest_states['texels']\n",
    "print(stat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "texture_maps = texels.detach().squeeze().cpu()\n",
    "td = texels.detach().cpu()\n",
    "print(td.shape)\n",
    "print(torch.min(td),',', torch.max(td))\n",
    "\n",
    "td_a = torch.clamp(-1.0*texture_maps, min=0.0)\n",
    "print('n_above:', torch.sum(td_a > 0.0))\n",
    "td_b = torch.clamp(texture_maps, min=1.0) - torch.ones(texture_maps.shape)\n",
    "print('n_below:', torch.sum(td_b > 1.0))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(td_a, vmin=0, vmax=1.0)\n",
    "ax[0].set_title('Pixels > 1.0')\n",
    "ax[1].imshow(td_b, vmin=0, vmax=1.0)\n",
    "ax[1].set_title('Pixels < 0.0')\n",
    "plt.figure()\n",
    "plt.imshow(td.clone().squeeze().numpy(), cmap='gray', vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save rendered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_dir = out_dir\n",
    "for i in range(len(images)):\n",
    "    print(' ', i+1, end='')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12), tight_layout=True)\n",
    "    img = images[i].detach().cpu().numpy()\n",
    "    ax[0].imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[1].imshow(img_refs[i], cmap='gray')\n",
    "    ax[1].invert_yaxis()\n",
    "    plt.savefig(save_dir + '/compare_cam{}.png'.format(i+1), dpi=300)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(16, 1, figsize=(15, 140))\n",
    "ax = ax.ravel()\n",
    "for i in range(len(ax)):\n",
    "    img_mesh = images_rendered[i]\n",
    "    img_mesh = cv2.flip(img_mesh, -1)\n",
    "    img_bg = image_refs[i]\n",
    "    img_bg = cv2.flip(img_bg, -1)\n",
    "    ax[i].imshow(img_bg)\n",
    "\n",
    "    img_mesh_large = np.zeros(img_bg.shape)\n",
    "    img_mesh_padded = cv2.copyMakeBorder(img_mesh, 0, 0, int((4000-2160)/2), int((4000-2160)/2), 0, None, [0, 0, 0])\n",
    "    ax[i].imshow(img_mesh, alpha=0.5)\n",
    "    \n",
    "    pts = mesh_points[i]\n",
    "    pts_small_x = (pts[:, 0] - (4000-2160)*0.5) * rendered_image_size/2160\n",
    "    pts_small_y = pts[:, 1] * rendered_image_size/2160\n",
    "    pts_small = np.stack([pts_small_x, pts_small_y]).T\n",
    "    pts_center = np.mean(pts_small, axis=0)\n",
    "#     ax[i].scatter(pts[:, 0], pts[:, 1], c='r', s=0.1)\n",
    "#     ax[i].scatter(pts_small[:, 0], pts_small[:, 1], c='r', s=0.01)\n",
    "    ax[i].set_title('Camera {}'.format(cams[i]))\n",
    "    \n",
    "    # plot centers\n",
    "    ax[i].scatter(pts_center[0], pts_center[1], c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, meshes, image_refs, renderers, texture_maps):\n",
    "        super().__init__()\n",
    "        self.meshes = meshes\n",
    "        self.device = meshes.device\n",
    "        self.renderers = renderers\n",
    "        self.register_buffer('image_refs', image_refs)\n",
    "\n",
    "        self.texture_maps = nn.Parameter(texture_maps.to(meshes.device), requires_grad=True)\n",
    "        \n",
    "    def forward(self):\n",
    "        loss = 0\n",
    "        images = []\n",
    "        for i in range(len(self.renderers)):\n",
    "            image = self.renderers[i](meshes_world=self.meshes, texture_maps=self.texture_maps)\n",
    "            loss_i = torch.mean((image.squeeze()[..., :3] - self.image_refs[i]) ** 2)\n",
    "            images.append(image)\n",
    "            loss = loss + loss_i\n",
    "        loss /= len(self.renderers)\n",
    "\n",
    "        return loss, images, self.texture_maps.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(model.texture_maps.detach().cpu().numpy()[0, :, :, :])\n",
    "plt.savefig('./4_data/output/4b/texturemap_learned.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1, 1), requires_grad=True)\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    print(prof)\n",
    "    for _ in range(100):  # any normal python code, really!\n",
    "        y = x ** 2\n",
    "        y.backward()\n",
    "# NOTE: some columns were removed for brevity\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_stats(device=device_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=device_gpu, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_stats = torch.cuda.memory_stats(device=device_gpu)\n",
    "for k, v in mem_stats.items():\n",
    "    print('{}: {}'.format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.max_memory_allocated(device=device_gpu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
