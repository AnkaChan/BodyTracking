{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:96% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/03 21:34:18]\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "import imageio\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "# Util function for loading meshes\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "import math\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Meshes, Textures\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    OpenGLPerspectiveCameras, \n",
    "    SfMPerspectiveCameras,\n",
    "    SfMOrthographicCameras,\n",
    "    PointLights, \n",
    "    DirectionalLights,\n",
    "    Materials, \n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer,  \n",
    "    TexturedSoftPhongShader,\n",
    "    SoftSilhouetteShader,\n",
    "    look_at_rotation,\n",
    "    HardFlatShader\n",
    ")\n",
    "\n",
    "# add path for demo utils functions \n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "sys.path.append(os.path.abspath(''))\n",
    "\n",
    "from datetime import datetime\n",
    "def now_str():\n",
    "    now = datetime.now()\n",
    "    month = str(now.month)\n",
    "    day = str(now.day)\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    sec = str(now.second)\n",
    "    \n",
    "    output = '[{:>02}/{:>02} {:>02}:{:>02}:{:>02}]'.format(month, day, hour, minute, sec)\n",
    "    return output\n",
    "def __output_log(path, strs):\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w+') as f:\n",
    "            f.write(strs)\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(path, 'a+') as f:\n",
    "            f.write(strs)\n",
    "            f.close()\n",
    "print(now_str())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "torch.cuda.current_device(): 0\n",
      "torch.cuda.get_device_name(0): GeForce RTX 2070 SUPER\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "torch.cuda.memory_reserved(): 0.00 Mb\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n",
      "----- torch.cuda.empty_cache() -----\n",
      "torch.cuda.memory_reserved(): 0.00 Mb\n",
      "torch.cuda.memory_allocated(): 0.00 Mb\n",
      "torch.cuda.memory_cached(): 0.00 Mb\n"
     ]
    }
   ],
   "source": [
    "print('torch.cuda.is_available():',torch.cuda.is_available())\n",
    "\n",
    "device_gpu = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(device_gpu)\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "print('torch.cuda.current_device():', torch.cuda.current_device())\n",
    "torch.cuda.ipc_collect()\n",
    "print('torch.cuda.get_device_name(0):',torch.cuda.get_device_name(0))\n",
    "\n",
    "# print('GPU memory stats ---------------------')\n",
    "# gpu_mem_stats = torch.cuda.memory_stats(device=device_gpu)\n",
    "# for k, v in gpu_mem_stats.items():\n",
    "#     print('  {}: {}'.format(k, v))\n",
    "\n",
    "print(torch.cuda.memory_summary(device=device_gpu, abbreviated=False))\n",
    "bytes_reserved = torch.cuda.memory_reserved()\n",
    "print('torch.cuda.memory_reserved(): {:,.2f} Mb'.format(bytes_reserved * 0.000001))\n",
    "# Returns the current GPU memory usage by \n",
    "# tensors in bytes for a given device\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "\n",
    "# Returns the current GPU memory managed by the\n",
    "# caching allocator in bytes for a given device\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))\n",
    "\n",
    "\n",
    "\n",
    "# Releases all unoccupied cached memory currently held by\n",
    "# the caching allocator so that those can be used in other\n",
    "# GPU application and visible in nvidia-smi\n",
    "print('----- torch.cuda.empty_cache() -----')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "bytes_reserved = torch.cuda.memory_reserved()\n",
    "print('torch.cuda.memory_reserved(): {:,.2f} Mb'.format(bytes_reserved * 0.000001))\n",
    "bytes_alloc = torch.cuda.memory_allocated()\n",
    "print('torch.cuda.memory_allocated(): {:,.2f} Mb'.format(bytes_alloc * 0.000001))\n",
    "bytes_cached = torch.cuda.memory_cached()\n",
    "print('torch.cuda.memory_cached(): {:,.2f} Mb'.format(bytes_cached * 0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Rz(r):\n",
    "    # r = rad\n",
    "    R = np.float32([[math.cos(r), -math.sin(r), 0], [math.sin(r), math.cos(r), 0], [0, 0, 1]])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.123234e-17  1.000000e+00  0.000000e+00]\n",
      " [-1.000000e+00  6.123234e-17  0.000000e+00]\n",
      " [ 0.000000e+00  0.000000e+00  1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# R = torch.from_numpy(np.identity(3).astype(np.float32)).unsqueeze(0)\n",
    "R_z = Rz(-np.pi/2)\n",
    "R = torch.from_numpy(R_z).unsqueeze(0)\n",
    "T = torch.from_numpy(np.array([0, 0, 0]).astype(np.float32)).unsqueeze(0)\n",
    "print(R_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if R is ext:               [ 6.123234e-16 -1.000000e+01  0.000000e+00]\n",
      "if R is ext, column_major: [6.123234e-16 1.000000e+01 0.000000e+00]\n",
      "\n",
      "if R is ext:               [1.000000e+01 6.123234e-16 0.000000e+00]\n",
      "if R is ext, column_major: [-1.000000e+01  6.123234e-16  0.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "p1 = np.float32([10, 0, 0])\n",
    "p2 = np.float32([0, 10, 0])\n",
    "p1b = R_z.dot(p1)\n",
    "p2b = R_z.dot(p2)\n",
    "p1b_column_major = p1.dot(R_z)\n",
    "p2b_column_major = p2.dot(R_z)\n",
    "print('if R is ext:              ', p1b)\n",
    "print('if R is ext, column_major:', p1b_column_major)\n",
    "print()\n",
    "print('if R is ext:              ', p2b)\n",
    "print('if R is ext, column_major:', p2b_column_major)\n",
    "ps = np.array([p1, p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  composed_matrix:\n",
      "[[ 6.123234e-17 -1.000000e+00  0.000000e+00  0.000000e+00]\n",
      " [ 1.000000e+00  6.123234e-17  0.000000e+00  0.000000e+00]\n",
      " [ 0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00]\n",
      " [ 0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00]]\n",
      "[[[ 6.123234e-16 -1.000000e+01  0.000000e+00]\n",
      "  [ 1.000000e+01  6.123234e-16  0.000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "principal_point = torch.from_numpy(np.array([1, 1]).astype(np.float32)).unsqueeze(0)\n",
    "focal_length = torch.from_numpy(np.array([0, 0]).astype(np.float32)).unsqueeze(0)\n",
    "camera = SfMPerspectiveCameras(device=device_cpu, R=R, T=T, principal_point=principal_point, focal_length=focal_length)\n",
    "E = camera.get_world_to_view_transform()\n",
    "psb = E.transform_points(torch.from_numpy(ps).unsqueeze(0))\n",
    "print(psb.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 transform_points. KE=\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 1. 1. 0.]]\n",
      "  composed_matrix:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 1. 1. 0.]]\n",
      "tensor([[[inf, inf, inf],\n",
      "         [inf, inf, inf]]])\n"
     ]
    }
   ],
   "source": [
    "# verts_world = torch.from_numpy(np.array([[-354.0330,  207.6380, 1707.0809], [-356.3820,  195.7520, 1695.5021]]).astype(np.float32)).unsqueeze(0)\n",
    "verts_world = torch.from_numpy(np.array([[100, 0, 0], [0, 0, 0]]).astype(np.float32)).unsqueeze(0)\n",
    "verts_screen = camera.transform_points(verts_world)\n",
    "print(verts_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproj_pytorch3d(camera, verts_world):\n",
    "    E = camera.get_world_to_view_transform().get_matrix()[0]\n",
    "\n",
    "    Kmtx = camera.get_projection_transform().get_matrix()[0]\n",
    "    fx = Kmtx[0, 0]\n",
    "    fy = Kmtx[1, 1]\n",
    "    px = Kmtx[3, 0]\n",
    "    py = Kmtx[3, 1]\n",
    "    \n",
    "    K = np.array([[fx,   0,    0,  0], [0,   fy,    0,  0], [0,    0,    0,   1], [px, py, 1, 0]])\n",
    "    print(K)\n",
    "    pts = verts_world.squeeze().numpy()\n",
    "    print(pts.shape)\n",
    "    for i in range(pts.shape[0]):\n",
    "        Vw = np.array([pts[i, 0], pts[i, 1], pts[i, 2], 1]).astype(np.float32)\n",
    "        \n",
    "        # extrinsics\n",
    "        Vc = Vw.dot(E)\n",
    "        \n",
    "        # intrinsics\n",
    "        U = Vc.dot(K)\n",
    "        U[0] /= U[3]\n",
    "        U[1] /= U[3]\n",
    "        \n",
    "        print(U)\n",
    "reproj_pytorch3d(camera, verts_world)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
